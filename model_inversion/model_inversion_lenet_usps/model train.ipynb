{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model train.ipynb","provenance":[],"mount_file_id":"1fy3xqfv73g0rgJjDwCTI_u3NIuEa6M7S","authorship_tag":"ABX9TyOJD0kXkjJT3rWXH8S+VIDk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BiO3TVc0x3Gl","executionInfo":{"status":"ok","timestamp":1640316039697,"user_tz":-480,"elapsed":5,"user":{"displayName":"吴岳洲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10140082103242733864"}},"outputId":"8c7175fa-a3d3-48e9-e4cd-8b028d6ca785"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/model inversion(lenet)\n"]}],"source":["cd \"drive/MyDrive/model inversion(lenet)\""]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)\n","\n","class Extractor(nn.Module):\n","\n","    def __init__(self):\n","        super(Extractor, self).__init__()\n","        self.extractor = nn.Sequential(\n","            nn.Conv2d(1, 6, 5),\n","            nn.AvgPool2d(2, 2),\n","            nn.Sigmoid(),\n","            nn.Conv2d(6, 16, 5),\n","            nn.AvgPool2d(2, 2),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        x = self.extractor(x)\n","        return x\n","\n","    \n","class Classifier(nn.Module):\n","\n","    def __init__(self, num_classes=10):\n","        super(Classifier, self).__init__()\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(16 * 5 * 5, 120),\n","            nn.Sigmoid(),\n","            nn.Linear(120, 84),\n","            nn.Sigmoid(),\n","            nn.Linear(84, num_classes),\n","        )\n","\n","    def forward(self, x):\n","        x = self.classifier(x)\n","        return x\n","\n","\n","class Generator(nn.Module):\n","\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.generator = nn.Sequential(\n","            nn.ConvTranspose2d(100 + 10, 512, 2, 1, 0),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(512, 256, 2, 1, 0),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(256, 128, 2, 1, 0),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(128, 16, 2, 1, 0),\n","            nn.Sigmoid(),\n","        )\n","        self.apply(weights_init)\n","        \n","    def forward(self, z, y):\n","        y = F.one_hot(y, 10)\n","        y = y.unsqueeze(-1).unsqueeze(-1)\n","        feat = torch.cat([z, y], 1)\n","        feat = self.generator(feat)\n","        return feat\n","    \n","    \n","class Discriminator(nn.Module):\n","\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.discriminator = nn.Sequential(\n","            nn.Conv2d(16 + 10, 128, 2, 1, 0),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(inplace=True),\n","            nn.Conv2d(128, 256, 2, 1, 0),\n","            nn.BatchNorm2d(256),\n","            nn.LeakyReLU(inplace=True),\n","            nn.Conv2d(256, 512, 2, 1, 0),\n","            nn.BatchNorm2d(512),\n","            nn.LeakyReLU(inplace=True),\n","            nn.Conv2d(512, 1, 2, 1, 0),\n","            nn.Sigmoid(),\n","        )\n","        self.apply(weights_init)\n","        \n","    def forward(self, feat, y):\n","        y = F.one_hot(y, 10)\n","        y = y.unsqueeze(-1).unsqueeze(-1)\n","        y = y.expand(y.size(0), 10, 5, 5)\n","        feat = torch.cat([feat, y], 1)\n","        feat = self.discriminator(feat)\n","        feat = feat.squeeze(-1).squeeze(-1)\n","        return feat"],"metadata":{"id":"s3WBnGOpyCdY","executionInfo":{"status":"ok","timestamp":1640316042210,"user_tz":-480,"elapsed":2516,"user":{"displayName":"吴岳洲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10140082103242733864"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader, Subset\n","from torchvision import transforms\n","import torchvision.datasets as datasets\n","import numpy as np\n","\n","transform=transforms.Compose([\n","    transforms.Resize([32, 32]),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5), (0.5)),\n","])\n","\n","usps_trainset = datasets.USPS(root='./data', train=True, download=True, transform=transform)\n","usps_testset = datasets.USPS(root='./data', train=False, download=True, transform=transform)\n","mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","\n","size = len(usps_trainset)\n","index = np.arange(size)\n","client_trainset = Subset(usps_trainset, index[:2000])\n","server_iid_trainset = Subset(usps_trainset, index[2000:4000])\n","server_niid_trainset = Subset(mnist_trainset, index[:2000])\n","\n","client_trainloader = DataLoader(client_trainset, batch_size=8, shuffle=True, num_workers=0, pin_memory=True)\n","server_iid_trainloader = DataLoader(server_iid_trainset, batch_size=8, shuffle=True, num_workers=0, pin_memory=True)\n","server_niid_trainloader = DataLoader(server_niid_trainset, batch_size=8, shuffle=True, num_workers=0, pin_memory=True)\n","\n","client_testloader = DataLoader(usps_testset, batch_size=8, shuffle=False, num_workers=0, pin_memory=True)\n","server_iid_testloader = DataLoader(usps_testset, batch_size=8, shuffle=False, num_workers=0, pin_memory=True)\n","server_niid_testloader = DataLoader(mnist_testset, batch_size=8, shuffle=False, num_workers=0, pin_memory=True)"],"metadata":{"id":"cZ0VLFMex767","executionInfo":{"status":"ok","timestamp":1640316047558,"user_tz":-480,"elapsed":5350,"user":{"displayName":"吴岳洲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10140082103242733864"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def get_params(net, modules):\n","    params = []\n","    for module in modules:\n","        params.append({\"params\": net[module].parameters()})\n","    return params\n","\n","def frozen_net(net, modules, frozen):\n","    for module in modules:\n","        for param in net[module].parameters():\n","            param.requires_grad = not frozen\n","        if frozen:\n","            net[module].eval()\n","        else:\n","            net[module].train()\n"],"metadata":{"id":"VbvFSIwRyEc0","executionInfo":{"status":"ok","timestamp":1640316047559,"user_tz":-480,"elapsed":4,"user":{"displayName":"吴岳洲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10140082103242733864"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["**client train**"],"metadata":{"id":"x-o2BJ-4_DmO"}},{"cell_type":"code","source":["net = nn.ModuleDict()\n","net[\"extractor\"] = Extractor()          \n","net[\"classifier\"] = Classifier()    \n","net = net.to(device)\n","frozen_net(net, [\"extractor\", \"classifier\"], True)\n","EC_optimizer = optim.Adam(get_params(net, [\"extractor\", \"classifier\"]), lr=3e-4, weight_decay=1e-4)\n","CE_criterion = nn.CrossEntropyLoss().to(device)\n","\n","for epoch in range(200):\n","    # train\n","    frozen_net(net, [\"extractor\", \"classifier\"], False)\n","    losses, batch = 0., 0\n","    for x, y in client_trainloader:\n","        x = x.to(device)\n","        y = y.to(device)\n","        \n","        EC_optimizer.zero_grad()\n","        E = net[\"extractor\"](x)\n","        EC = net[\"classifier\"](E)\n","        loss = CE_criterion(EC, y)\n","        loss.backward()\n","        EC_optimizer.step()\n","\n","        losses += loss.item()\n","        batch += 1\n","    avg_loss = losses / batch\n","    frozen_net(net, [\"extractor\", \"classifier\"], True)\n","    \n","\n","    # test\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","        for x, y in client_testloader:\n","            x = x.to(device)\n","            y = y.to(device)\n","\n","            E = net[\"extractor\"](x)\n","            EC = net[\"classifier\"](E)\n","\n","            correct += torch.sum((torch.argmax(EC, dim=1) == y).float()).item()\n","            total += x.size(0)\n","    acc = correct / total\n","\n","    print(\"epoch:[%2d], loss:%2.6f, acc:%2.6f\"%(epoch, avg_loss, acc))\n","\n","torch.save(net[\"extractor\"].state_dict(), \"./checkpoint/client_extractor.pkl\")\n","torch.save(net[\"classifier\"].state_dict(), \"./checkpoint/client_classifier.pkl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60HzDW-EyM3y","executionInfo":{"status":"ok","timestamp":1640316439812,"user_tz":-480,"elapsed":392256,"user":{"displayName":"吴岳洲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10140082103242733864"}},"outputId":"95a5767f-46b4-4d17-994d-f7ef255aeb0f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:[ 0], loss:2.242679, acc:0.178874\n","epoch:[ 1], loss:2.227359, acc:0.178874\n","epoch:[ 2], loss:2.121932, acc:0.304933\n","epoch:[ 3], loss:1.721823, acc:0.410563\n","epoch:[ 4], loss:1.392067, acc:0.524165\n","epoch:[ 5], loss:1.150464, acc:0.617339\n","epoch:[ 6], loss:0.964922, acc:0.695566\n","epoch:[ 7], loss:0.811933, acc:0.723966\n","epoch:[ 8], loss:0.687541, acc:0.763328\n","epoch:[ 9], loss:0.587486, acc:0.781266\n","epoch:[10], loss:0.512632, acc:0.813154\n","epoch:[11], loss:0.455462, acc:0.821624\n","epoch:[12], loss:0.409748, acc:0.830095\n","epoch:[13], loss:0.368186, acc:0.831589\n","epoch:[14], loss:0.338250, acc:0.833084\n","epoch:[15], loss:0.311000, acc:0.840060\n","epoch:[16], loss:0.287012, acc:0.848032\n","epoch:[17], loss:0.266204, acc:0.841555\n","epoch:[18], loss:0.248980, acc:0.857000\n","epoch:[19], loss:0.233034, acc:0.859492\n","epoch:[20], loss:0.220193, acc:0.866966\n","epoch:[21], loss:0.207648, acc:0.865471\n","epoch:[22], loss:0.194856, acc:0.875436\n","epoch:[23], loss:0.186172, acc:0.871948\n","epoch:[24], loss:0.173073, acc:0.870952\n","epoch:[25], loss:0.162371, acc:0.884405\n","epoch:[26], loss:0.156518, acc:0.885899\n","epoch:[27], loss:0.146506, acc:0.882910\n","epoch:[28], loss:0.140370, acc:0.878426\n","epoch:[29], loss:0.132241, acc:0.894370\n","epoch:[30], loss:0.126054, acc:0.885899\n","epoch:[31], loss:0.118878, acc:0.893871\n","epoch:[32], loss:0.115712, acc:0.897857\n","epoch:[33], loss:0.107041, acc:0.893871\n","epoch:[34], loss:0.102400, acc:0.894868\n","epoch:[35], loss:0.098094, acc:0.896861\n","epoch:[36], loss:0.095199, acc:0.898854\n","epoch:[37], loss:0.091108, acc:0.899851\n","epoch:[38], loss:0.086427, acc:0.897359\n","epoch:[39], loss:0.081826, acc:0.900847\n","epoch:[40], loss:0.079402, acc:0.900847\n","epoch:[41], loss:0.076332, acc:0.900349\n","epoch:[42], loss:0.071106, acc:0.899851\n","epoch:[43], loss:0.069860, acc:0.906328\n","epoch:[44], loss:0.064598, acc:0.906826\n","epoch:[45], loss:0.061951, acc:0.902840\n","epoch:[46], loss:0.059351, acc:0.905331\n","epoch:[47], loss:0.058092, acc:0.907823\n","epoch:[48], loss:0.055349, acc:0.906826\n","epoch:[49], loss:0.052733, acc:0.903837\n","epoch:[50], loss:0.050035, acc:0.905331\n","epoch:[51], loss:0.050165, acc:0.910314\n","epoch:[52], loss:0.044866, acc:0.909816\n","epoch:[53], loss:0.045596, acc:0.911809\n","epoch:[54], loss:0.041719, acc:0.910812\n","epoch:[55], loss:0.040783, acc:0.908819\n","epoch:[56], loss:0.039066, acc:0.911310\n","epoch:[57], loss:0.036417, acc:0.913802\n","epoch:[58], loss:0.036581, acc:0.910314\n","epoch:[59], loss:0.033308, acc:0.913303\n","epoch:[60], loss:0.032225, acc:0.906826\n","epoch:[61], loss:0.031444, acc:0.914300\n","epoch:[62], loss:0.029724, acc:0.914300\n","epoch:[63], loss:0.026695, acc:0.908819\n","epoch:[64], loss:0.027009, acc:0.912307\n","epoch:[65], loss:0.026224, acc:0.914798\n","epoch:[66], loss:0.025310, acc:0.916293\n","epoch:[67], loss:0.023907, acc:0.916293\n","epoch:[68], loss:0.022550, acc:0.913802\n","epoch:[69], loss:0.025362, acc:0.911809\n","epoch:[70], loss:0.022024, acc:0.912805\n","epoch:[71], loss:0.020579, acc:0.914798\n","epoch:[72], loss:0.019243, acc:0.909816\n","epoch:[73], loss:0.018316, acc:0.914798\n","epoch:[74], loss:0.021440, acc:0.911809\n","epoch:[75], loss:0.018992, acc:0.912307\n","epoch:[76], loss:0.016942, acc:0.917788\n","epoch:[77], loss:0.017611, acc:0.913303\n","epoch:[78], loss:0.017704, acc:0.917788\n","epoch:[79], loss:0.015550, acc:0.914300\n","epoch:[80], loss:0.014217, acc:0.914300\n","epoch:[81], loss:0.015911, acc:0.916293\n","epoch:[82], loss:0.014546, acc:0.915296\n","epoch:[83], loss:0.014275, acc:0.915795\n","epoch:[84], loss:0.013361, acc:0.913802\n","epoch:[85], loss:0.016349, acc:0.914798\n","epoch:[86], loss:0.013611, acc:0.912307\n","epoch:[87], loss:0.013888, acc:0.917788\n","epoch:[88], loss:0.013086, acc:0.913802\n","epoch:[89], loss:0.012133, acc:0.917289\n","epoch:[90], loss:0.013131, acc:0.917788\n","epoch:[91], loss:0.013521, acc:0.915795\n","epoch:[92], loss:0.010978, acc:0.913303\n","epoch:[93], loss:0.011026, acc:0.916791\n","epoch:[94], loss:0.012185, acc:0.918784\n","epoch:[95], loss:0.010312, acc:0.917788\n","epoch:[96], loss:0.010343, acc:0.919283\n","epoch:[97], loss:0.011332, acc:0.912805\n","epoch:[98], loss:0.010300, acc:0.913303\n","epoch:[99], loss:0.010871, acc:0.913802\n","epoch:[100], loss:0.011762, acc:0.920279\n","epoch:[101], loss:0.010055, acc:0.905830\n","epoch:[102], loss:0.010176, acc:0.916791\n","epoch:[103], loss:0.009588, acc:0.913802\n","epoch:[104], loss:0.011263, acc:0.915795\n","epoch:[105], loss:0.009675, acc:0.908819\n","epoch:[106], loss:0.011241, acc:0.917289\n","epoch:[107], loss:0.010309, acc:0.910812\n","epoch:[108], loss:0.008703, acc:0.917289\n","epoch:[109], loss:0.008263, acc:0.914798\n","epoch:[110], loss:0.008356, acc:0.916293\n","epoch:[111], loss:0.009222, acc:0.917289\n","epoch:[112], loss:0.008712, acc:0.917788\n","epoch:[113], loss:0.011764, acc:0.912805\n","epoch:[114], loss:0.009164, acc:0.917289\n","epoch:[115], loss:0.008375, acc:0.912307\n","epoch:[116], loss:0.010008, acc:0.912307\n","epoch:[117], loss:0.009946, acc:0.914300\n","epoch:[118], loss:0.007580, acc:0.915795\n","epoch:[119], loss:0.007632, acc:0.914798\n","epoch:[120], loss:0.008205, acc:0.914798\n","epoch:[121], loss:0.010122, acc:0.913802\n","epoch:[122], loss:0.009884, acc:0.912805\n","epoch:[123], loss:0.008010, acc:0.915795\n","epoch:[124], loss:0.008063, acc:0.917289\n","epoch:[125], loss:0.009329, acc:0.915795\n","epoch:[126], loss:0.008008, acc:0.917788\n","epoch:[127], loss:0.007861, acc:0.909317\n","epoch:[128], loss:0.009228, acc:0.916293\n","epoch:[129], loss:0.007875, acc:0.915296\n","epoch:[130], loss:0.008193, acc:0.916293\n","epoch:[131], loss:0.007655, acc:0.916293\n","epoch:[132], loss:0.007440, acc:0.915296\n","epoch:[133], loss:0.006902, acc:0.914798\n","epoch:[134], loss:0.009635, acc:0.915795\n","epoch:[135], loss:0.007865, acc:0.914798\n","epoch:[136], loss:0.009427, acc:0.920279\n","epoch:[137], loss:0.006967, acc:0.919283\n","epoch:[138], loss:0.007038, acc:0.918784\n","epoch:[139], loss:0.007621, acc:0.916293\n","epoch:[140], loss:0.007394, acc:0.912805\n","epoch:[141], loss:0.007116, acc:0.917788\n","epoch:[142], loss:0.009060, acc:0.916293\n","epoch:[143], loss:0.006879, acc:0.917788\n","epoch:[144], loss:0.008445, acc:0.919781\n","epoch:[145], loss:0.008315, acc:0.916293\n","epoch:[146], loss:0.008116, acc:0.915795\n","epoch:[147], loss:0.006255, acc:0.915296\n","epoch:[148], loss:0.006885, acc:0.916791\n","epoch:[149], loss:0.007084, acc:0.918784\n","epoch:[150], loss:0.007365, acc:0.917289\n","epoch:[151], loss:0.007842, acc:0.918286\n","epoch:[152], loss:0.008013, acc:0.921774\n","epoch:[153], loss:0.006605, acc:0.911809\n","epoch:[154], loss:0.006722, acc:0.917289\n","epoch:[155], loss:0.009556, acc:0.917289\n","epoch:[156], loss:0.007408, acc:0.916791\n","epoch:[157], loss:0.008008, acc:0.916293\n","epoch:[158], loss:0.007347, acc:0.915795\n","epoch:[159], loss:0.006916, acc:0.910812\n","epoch:[160], loss:0.006856, acc:0.916791\n","epoch:[161], loss:0.006553, acc:0.918784\n","epoch:[162], loss:0.007421, acc:0.913802\n","epoch:[163], loss:0.006803, acc:0.918784\n","epoch:[164], loss:0.013880, acc:0.915296\n","epoch:[165], loss:0.006049, acc:0.914798\n","epoch:[166], loss:0.005528, acc:0.918286\n","epoch:[167], loss:0.006899, acc:0.920777\n","epoch:[168], loss:0.006253, acc:0.919283\n","epoch:[169], loss:0.006118, acc:0.916791\n","epoch:[170], loss:0.005798, acc:0.916791\n","epoch:[171], loss:0.011677, acc:0.918784\n","epoch:[172], loss:0.006235, acc:0.917788\n","epoch:[173], loss:0.005859, acc:0.918784\n","epoch:[174], loss:0.005715, acc:0.918286\n","epoch:[175], loss:0.005794, acc:0.919781\n","epoch:[176], loss:0.006059, acc:0.919781\n","epoch:[177], loss:0.007470, acc:0.917788\n","epoch:[178], loss:0.007702, acc:0.904335\n","epoch:[179], loss:0.012380, acc:0.915296\n","epoch:[180], loss:0.008036, acc:0.918286\n","epoch:[181], loss:0.007039, acc:0.916791\n","epoch:[182], loss:0.005321, acc:0.916293\n","epoch:[183], loss:0.005616, acc:0.921774\n","epoch:[184], loss:0.005895, acc:0.917788\n","epoch:[185], loss:0.005652, acc:0.918286\n","epoch:[186], loss:0.007456, acc:0.919283\n","epoch:[187], loss:0.006369, acc:0.914798\n","epoch:[188], loss:0.008175, acc:0.913802\n","epoch:[189], loss:0.007580, acc:0.920279\n","epoch:[190], loss:0.007255, acc:0.919283\n","epoch:[191], loss:0.006469, acc:0.920777\n","epoch:[192], loss:0.005989, acc:0.918286\n","epoch:[193], loss:0.006352, acc:0.918286\n","epoch:[194], loss:0.005687, acc:0.915795\n","epoch:[195], loss:0.006165, acc:0.922272\n","epoch:[196], loss:0.007991, acc:0.912307\n","epoch:[197], loss:0.007384, acc:0.914300\n","epoch:[198], loss:0.006100, acc:0.916791\n","epoch:[199], loss:0.005480, acc:0.919781\n"]}]},{"cell_type":"markdown","source":["**server same train**"],"metadata":{"id":"rZSfcmIxIc3B"}},{"cell_type":"code","source":["net = nn.ModuleDict()\n","net[\"extractor\"] = Extractor()          \n","net[\"classifier\"] = Classifier()    \n","net = net.to(device)\n","frozen_net(net, [\"extractor\", \"classifier\"], True)\n","E_optimizer = optim.Adam(get_params(net, [\"extractor\"]), lr=3e-4, weight_decay=1e-4)\n","CE_criterion = nn.CrossEntropyLoss().to(device)\n","\n","C_checkpoint = torch.load(\"./checkpoint/client_classifier.pkl\", map_location=torch.device('cpu'))\n","net[\"classifier\"].load_state_dict(C_checkpoint)\n","\n","for epoch in range(200):\n","    # train\n","    frozen_net(net, [\"extractor\"], False)\n","    losses, batch = 0., 0\n","    for x, y in client_trainloader:\n","        x = x.to(device)\n","        y = y.to(device)\n","        \n","        E_optimizer.zero_grad()\n","        E = net[\"extractor\"](x)\n","        EC = net[\"classifier\"](E)\n","        loss = CE_criterion(EC, y)\n","        loss.backward()\n","        E_optimizer.step()\n","\n","        losses += loss.item()\n","        batch += 1\n","    avg_loss = losses / batch\n","    frozen_net(net, [\"extractor\"], True)\n","    \n","\n","    # test\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","        for x, y in client_trainloader:\n","            x = x.to(device)\n","            y = y.to(device)\n","\n","            E = net[\"extractor\"](x)\n","            EC = net[\"classifier\"](E)\n","\n","            correct += torch.sum((torch.argmax(EC, dim=1) == y).float()).item()\n","            total += x.size(0)\n","    acc = correct / total\n","\n","    print(\"epoch:[%2d], loss:%2.6f, acc:%2.6f\"%(epoch, avg_loss, acc))\n","\n","torch.save(net[\"extractor\"].state_dict(), \"./checkpoint/server_same_extractor.pkl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIeNU2djIfUx","executionInfo":{"status":"ok","timestamp":1640316790571,"user_tz":-480,"elapsed":350762,"user":{"displayName":"吴岳洲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10140082103242733864"}},"outputId":"74f4e2bc-b81e-4cc0-df3f-9f3fe36e578f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:[ 0], loss:2.085667, acc:0.788000\n","epoch:[ 1], loss:0.710419, acc:0.879000\n","epoch:[ 2], loss:0.436361, acc:0.910500\n","epoch:[ 3], loss:0.333468, acc:0.915500\n","epoch:[ 4], loss:0.280116, acc:0.930500\n","epoch:[ 5], loss:0.241661, acc:0.937000\n","epoch:[ 6], loss:0.215050, acc:0.942000\n","epoch:[ 7], loss:0.189953, acc:0.947000\n","epoch:[ 8], loss:0.171485, acc:0.952000\n","epoch:[ 9], loss:0.155122, acc:0.953500\n","epoch:[10], loss:0.141446, acc:0.959000\n","epoch:[11], loss:0.128736, acc:0.965000\n","epoch:[12], loss:0.116980, acc:0.966500\n","epoch:[13], loss:0.107188, acc:0.971000\n","epoch:[14], loss:0.097588, acc:0.973000\n","epoch:[15], loss:0.089349, acc:0.976500\n","epoch:[16], loss:0.082594, acc:0.977000\n","epoch:[17], loss:0.075743, acc:0.980000\n","epoch:[18], loss:0.070746, acc:0.983500\n","epoch:[19], loss:0.065320, acc:0.985000\n","epoch:[20], loss:0.060564, acc:0.985500\n","epoch:[21], loss:0.055945, acc:0.989500\n","epoch:[22], loss:0.051590, acc:0.991500\n","epoch:[23], loss:0.048045, acc:0.991500\n","epoch:[24], loss:0.045152, acc:0.994000\n","epoch:[25], loss:0.041414, acc:0.993000\n","epoch:[26], loss:0.038750, acc:0.994500\n","epoch:[27], loss:0.037041, acc:0.996500\n","epoch:[28], loss:0.035016, acc:0.995500\n","epoch:[29], loss:0.031891, acc:0.997500\n","epoch:[30], loss:0.030347, acc:0.998000\n","epoch:[31], loss:0.028520, acc:0.999500\n","epoch:[32], loss:0.026896, acc:0.999000\n","epoch:[33], loss:0.025039, acc:0.999000\n","epoch:[34], loss:0.024260, acc:1.000000\n","epoch:[35], loss:0.022551, acc:0.999500\n","epoch:[36], loss:0.021825, acc:1.000000\n","epoch:[37], loss:0.020623, acc:0.999500\n","epoch:[38], loss:0.019511, acc:1.000000\n","epoch:[39], loss:0.018447, acc:1.000000\n","epoch:[40], loss:0.017653, acc:1.000000\n","epoch:[41], loss:0.016804, acc:1.000000\n","epoch:[42], loss:0.016246, acc:1.000000\n","epoch:[43], loss:0.015559, acc:1.000000\n","epoch:[44], loss:0.015131, acc:1.000000\n","epoch:[45], loss:0.014488, acc:1.000000\n","epoch:[46], loss:0.013843, acc:1.000000\n","epoch:[47], loss:0.013357, acc:1.000000\n","epoch:[48], loss:0.012981, acc:1.000000\n","epoch:[49], loss:0.012451, acc:1.000000\n","epoch:[50], loss:0.012225, acc:1.000000\n","epoch:[51], loss:0.011872, acc:1.000000\n","epoch:[52], loss:0.011240, acc:1.000000\n","epoch:[53], loss:0.011080, acc:1.000000\n","epoch:[54], loss:0.010741, acc:1.000000\n","epoch:[55], loss:0.010482, acc:1.000000\n","epoch:[56], loss:0.010084, acc:1.000000\n","epoch:[57], loss:0.009783, acc:1.000000\n","epoch:[58], loss:0.009646, acc:1.000000\n","epoch:[59], loss:0.009380, acc:1.000000\n","epoch:[60], loss:0.009234, acc:1.000000\n","epoch:[61], loss:0.009072, acc:1.000000\n","epoch:[62], loss:0.008794, acc:1.000000\n","epoch:[63], loss:0.008630, acc:1.000000\n","epoch:[64], loss:0.008520, acc:1.000000\n","epoch:[65], loss:0.008381, acc:1.000000\n","epoch:[66], loss:0.008283, acc:1.000000\n","epoch:[67], loss:0.007945, acc:1.000000\n","epoch:[68], loss:0.007858, acc:1.000000\n","epoch:[69], loss:0.007701, acc:1.000000\n","epoch:[70], loss:0.007584, acc:1.000000\n","epoch:[71], loss:0.007383, acc:1.000000\n","epoch:[72], loss:0.007446, acc:1.000000\n","epoch:[73], loss:0.007084, acc:1.000000\n","epoch:[74], loss:0.007234, acc:1.000000\n","epoch:[75], loss:0.007081, acc:1.000000\n","epoch:[76], loss:0.007001, acc:1.000000\n","epoch:[77], loss:0.006902, acc:1.000000\n","epoch:[78], loss:0.006880, acc:1.000000\n","epoch:[79], loss:0.006859, acc:1.000000\n","epoch:[80], loss:0.006629, acc:1.000000\n","epoch:[81], loss:0.006580, acc:1.000000\n","epoch:[82], loss:0.006600, acc:1.000000\n","epoch:[83], loss:0.006446, acc:1.000000\n","epoch:[84], loss:0.006401, acc:1.000000\n","epoch:[85], loss:0.006402, acc:1.000000\n","epoch:[86], loss:0.006312, acc:1.000000\n","epoch:[87], loss:0.006196, acc:1.000000\n","epoch:[88], loss:0.006277, acc:1.000000\n","epoch:[89], loss:0.006080, acc:1.000000\n","epoch:[90], loss:0.006144, acc:1.000000\n","epoch:[91], loss:0.006060, acc:1.000000\n","epoch:[92], loss:0.006031, acc:1.000000\n","epoch:[93], loss:0.005948, acc:1.000000\n","epoch:[94], loss:0.005798, acc:1.000000\n","epoch:[95], loss:0.005959, acc:1.000000\n","epoch:[96], loss:0.005967, acc:1.000000\n","epoch:[97], loss:0.005797, acc:1.000000\n","epoch:[98], loss:0.005808, acc:1.000000\n","epoch:[99], loss:0.005707, acc:1.000000\n","epoch:[100], loss:0.005706, acc:1.000000\n","epoch:[101], loss:0.005733, acc:1.000000\n","epoch:[102], loss:0.005634, acc:1.000000\n","epoch:[103], loss:0.005755, acc:1.000000\n","epoch:[104], loss:0.005574, acc:1.000000\n","epoch:[105], loss:0.005565, acc:1.000000\n","epoch:[106], loss:0.005651, acc:1.000000\n","epoch:[107], loss:0.005503, acc:1.000000\n","epoch:[108], loss:0.005671, acc:1.000000\n","epoch:[109], loss:0.005600, acc:1.000000\n","epoch:[110], loss:0.005445, acc:1.000000\n","epoch:[111], loss:0.005489, acc:1.000000\n","epoch:[112], loss:0.005519, acc:1.000000\n","epoch:[113], loss:0.005500, acc:1.000000\n","epoch:[114], loss:0.005400, acc:1.000000\n","epoch:[115], loss:0.005415, acc:1.000000\n","epoch:[116], loss:0.005408, acc:1.000000\n","epoch:[117], loss:0.005454, acc:1.000000\n","epoch:[118], loss:0.005428, acc:1.000000\n","epoch:[119], loss:0.005402, acc:1.000000\n","epoch:[120], loss:0.005302, acc:1.000000\n","epoch:[121], loss:0.005327, acc:1.000000\n","epoch:[122], loss:0.005314, acc:1.000000\n","epoch:[123], loss:0.005305, acc:1.000000\n","epoch:[124], loss:0.005354, acc:1.000000\n","epoch:[125], loss:0.005342, acc:1.000000\n","epoch:[126], loss:0.005278, acc:1.000000\n","epoch:[127], loss:0.005271, acc:1.000000\n","epoch:[128], loss:0.005221, acc:1.000000\n","epoch:[129], loss:0.005175, acc:1.000000\n","epoch:[130], loss:0.005241, acc:1.000000\n","epoch:[131], loss:0.005203, acc:1.000000\n","epoch:[132], loss:0.005190, acc:1.000000\n","epoch:[133], loss:0.005111, acc:1.000000\n","epoch:[134], loss:0.005123, acc:1.000000\n","epoch:[135], loss:0.005149, acc:1.000000\n","epoch:[136], loss:0.005153, acc:1.000000\n","epoch:[137], loss:0.005202, acc:1.000000\n","epoch:[138], loss:0.005126, acc:1.000000\n","epoch:[139], loss:0.005089, acc:1.000000\n","epoch:[140], loss:0.005136, acc:1.000000\n","epoch:[141], loss:0.005110, acc:1.000000\n","epoch:[142], loss:0.005129, acc:1.000000\n","epoch:[143], loss:0.005049, acc:1.000000\n","epoch:[144], loss:0.005148, acc:1.000000\n","epoch:[145], loss:0.005106, acc:1.000000\n","epoch:[146], loss:0.005048, acc:1.000000\n","epoch:[147], loss:0.005139, acc:1.000000\n","epoch:[148], loss:0.005036, acc:1.000000\n","epoch:[149], loss:0.005090, acc:1.000000\n","epoch:[150], loss:0.005096, acc:1.000000\n","epoch:[151], loss:0.005015, acc:1.000000\n","epoch:[152], loss:0.005015, acc:1.000000\n","epoch:[153], loss:0.005169, acc:1.000000\n","epoch:[154], loss:0.005096, acc:1.000000\n","epoch:[155], loss:0.005021, acc:1.000000\n","epoch:[156], loss:0.005093, acc:1.000000\n","epoch:[157], loss:0.005015, acc:1.000000\n","epoch:[158], loss:0.005019, acc:1.000000\n","epoch:[159], loss:0.005020, acc:1.000000\n","epoch:[160], loss:0.004943, acc:1.000000\n","epoch:[161], loss:0.004963, acc:1.000000\n","epoch:[162], loss:0.005018, acc:1.000000\n","epoch:[163], loss:0.005042, acc:1.000000\n","epoch:[164], loss:0.004972, acc:1.000000\n","epoch:[165], loss:0.004979, acc:1.000000\n","epoch:[166], loss:0.004994, acc:1.000000\n","epoch:[167], loss:0.004983, acc:1.000000\n","epoch:[168], loss:0.004937, acc:1.000000\n","epoch:[169], loss:0.004994, acc:1.000000\n","epoch:[170], loss:0.004939, acc:1.000000\n","epoch:[171], loss:0.004899, acc:1.000000\n","epoch:[172], loss:0.004960, acc:1.000000\n","epoch:[173], loss:0.004977, acc:1.000000\n","epoch:[174], loss:0.004972, acc:1.000000\n","epoch:[175], loss:0.004998, acc:1.000000\n","epoch:[176], loss:0.004882, acc:1.000000\n","epoch:[177], loss:0.004961, acc:1.000000\n","epoch:[178], loss:0.004882, acc:1.000000\n","epoch:[179], loss:0.004923, acc:1.000000\n","epoch:[180], loss:0.004940, acc:1.000000\n","epoch:[181], loss:0.004973, acc:1.000000\n","epoch:[182], loss:0.004985, acc:1.000000\n","epoch:[183], loss:0.004969, acc:1.000000\n","epoch:[184], loss:0.004926, acc:1.000000\n","epoch:[185], loss:0.004952, acc:1.000000\n","epoch:[186], loss:0.004883, acc:1.000000\n","epoch:[187], loss:0.004840, acc:1.000000\n","epoch:[188], loss:0.004910, acc:1.000000\n","epoch:[189], loss:0.004912, acc:1.000000\n","epoch:[190], loss:0.004961, acc:1.000000\n","epoch:[191], loss:0.004941, acc:1.000000\n","epoch:[192], loss:0.004902, acc:1.000000\n","epoch:[193], loss:0.004937, acc:1.000000\n","epoch:[194], loss:0.004915, acc:1.000000\n","epoch:[195], loss:0.004922, acc:1.000000\n","epoch:[196], loss:0.004941, acc:1.000000\n","epoch:[197], loss:0.004907, acc:1.000000\n","epoch:[198], loss:0.004821, acc:1.000000\n","epoch:[199], loss:0.004998, acc:1.000000\n"]}]},{"cell_type":"markdown","source":["**server iid train**"],"metadata":{"id":"XkgJ-Z6M_KSw"}},{"cell_type":"code","source":["net = nn.ModuleDict()\n","net[\"extractor\"] = Extractor()          \n","net[\"classifier\"] = Classifier()    \n","net = net.to(device)\n","frozen_net(net, [\"extractor\", \"classifier\"], True)\n","E_optimizer = optim.Adam(get_params(net, [\"extractor\"]), lr=3e-4, weight_decay=1e-4)\n","CE_criterion = nn.CrossEntropyLoss().to(device)\n","\n","C_checkpoint = torch.load(\"./checkpoint/client_classifier.pkl\", map_location=torch.device('cpu'))\n","net[\"classifier\"].load_state_dict(C_checkpoint)\n","\n","for epoch in range(200):\n","    # train\n","    frozen_net(net, [\"extractor\"], False)\n","    losses, batch = 0., 0\n","    for x, y in server_iid_trainloader:\n","        x = x.to(device)\n","        y = y.to(device)\n","        \n","        E_optimizer.zero_grad()\n","        E = net[\"extractor\"](x)\n","        EC = net[\"classifier\"](E)\n","        loss = CE_criterion(EC, y)\n","        loss.backward()\n","        E_optimizer.step()\n","\n","        losses += loss.item()\n","        batch += 1\n","    avg_loss = losses / batch\n","    frozen_net(net, [\"extractor\"], True)\n","    \n","\n","    # test\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","        for x, y in server_iid_testloader:\n","            x = x.to(device)\n","            y = y.to(device)\n","\n","            E = net[\"extractor\"](x)\n","            EC = net[\"classifier\"](E)\n","\n","            correct += torch.sum((torch.argmax(EC, dim=1) == y).float()).item()\n","            total += x.size(0)\n","    acc = correct / total\n","\n","    print(\"epoch:[%2d], loss:%2.6f, acc:%2.6f\"%(epoch, avg_loss, acc))\n","\n","torch.save(net[\"extractor\"].state_dict(), \"./checkpoint/server_iid_extractor.pkl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gq_glU2S1myq","executionInfo":{"status":"ok","timestamp":1640317138001,"user_tz":-480,"elapsed":347434,"user":{"displayName":"吴岳洲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10140082103242733864"}},"outputId":"c11e6d80-f82d-4c7e-d3e8-84db93fbbba3"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:[ 0], loss:2.560075, acc:0.595914\n","epoch:[ 1], loss:0.899974, acc:0.798705\n","epoch:[ 2], loss:0.568349, acc:0.836074\n","epoch:[ 3], loss:0.466450, acc:0.848032\n","epoch:[ 4], loss:0.408821, acc:0.862481\n","epoch:[ 5], loss:0.375343, acc:0.866467\n","epoch:[ 6], loss:0.352817, acc:0.869955\n","epoch:[ 7], loss:0.334721, acc:0.880917\n","epoch:[ 8], loss:0.316965, acc:0.876931\n","epoch:[ 9], loss:0.305257, acc:0.878924\n","epoch:[10], loss:0.291816, acc:0.883408\n","epoch:[11], loss:0.283862, acc:0.882910\n","epoch:[12], loss:0.273320, acc:0.886896\n","epoch:[13], loss:0.266966, acc:0.891380\n","epoch:[14], loss:0.257533, acc:0.895864\n","epoch:[15], loss:0.252224, acc:0.896363\n","epoch:[16], loss:0.246025, acc:0.896861\n","epoch:[17], loss:0.242286, acc:0.898356\n","epoch:[18], loss:0.236872, acc:0.900349\n","epoch:[19], loss:0.231795, acc:0.900847\n","epoch:[20], loss:0.228103, acc:0.902840\n","epoch:[21], loss:0.227216, acc:0.902342\n","epoch:[22], loss:0.222275, acc:0.904335\n","epoch:[23], loss:0.218293, acc:0.901345\n","epoch:[24], loss:0.217492, acc:0.900847\n","epoch:[25], loss:0.211512, acc:0.904335\n","epoch:[26], loss:0.213715, acc:0.907823\n","epoch:[27], loss:0.206855, acc:0.905830\n","epoch:[28], loss:0.208744, acc:0.906328\n","epoch:[29], loss:0.204427, acc:0.905830\n","epoch:[30], loss:0.203416, acc:0.909317\n","epoch:[31], loss:0.201419, acc:0.908321\n","epoch:[32], loss:0.199788, acc:0.908321\n","epoch:[33], loss:0.198816, acc:0.909317\n","epoch:[34], loss:0.197295, acc:0.905830\n","epoch:[35], loss:0.193282, acc:0.908819\n","epoch:[36], loss:0.193274, acc:0.909317\n","epoch:[37], loss:0.191969, acc:0.910314\n","epoch:[38], loss:0.190001, acc:0.910812\n","epoch:[39], loss:0.188541, acc:0.908819\n","epoch:[40], loss:0.188273, acc:0.909816\n","epoch:[41], loss:0.187250, acc:0.911809\n","epoch:[42], loss:0.183762, acc:0.912307\n","epoch:[43], loss:0.183606, acc:0.911809\n","epoch:[44], loss:0.183088, acc:0.912307\n","epoch:[45], loss:0.183432, acc:0.910812\n","epoch:[46], loss:0.181954, acc:0.915296\n","epoch:[47], loss:0.182078, acc:0.911310\n","epoch:[48], loss:0.179163, acc:0.912805\n","epoch:[49], loss:0.179130, acc:0.911809\n","epoch:[50], loss:0.178406, acc:0.914798\n","epoch:[51], loss:0.177277, acc:0.915296\n","epoch:[52], loss:0.176585, acc:0.914798\n","epoch:[53], loss:0.175253, acc:0.914798\n","epoch:[54], loss:0.173541, acc:0.915795\n","epoch:[55], loss:0.173405, acc:0.917289\n","epoch:[56], loss:0.174081, acc:0.916791\n","epoch:[57], loss:0.172321, acc:0.918286\n","epoch:[58], loss:0.171328, acc:0.917289\n","epoch:[59], loss:0.170407, acc:0.915296\n","epoch:[60], loss:0.169193, acc:0.916791\n","epoch:[61], loss:0.169449, acc:0.917788\n","epoch:[62], loss:0.169007, acc:0.917788\n","epoch:[63], loss:0.167247, acc:0.920279\n","epoch:[64], loss:0.166515, acc:0.917788\n","epoch:[65], loss:0.165732, acc:0.918286\n","epoch:[66], loss:0.165557, acc:0.917289\n","epoch:[67], loss:0.165438, acc:0.915795\n","epoch:[68], loss:0.163977, acc:0.917788\n","epoch:[69], loss:0.162871, acc:0.919283\n","epoch:[70], loss:0.163114, acc:0.918784\n","epoch:[71], loss:0.162886, acc:0.919781\n","epoch:[72], loss:0.160748, acc:0.920279\n","epoch:[73], loss:0.162251, acc:0.918286\n","epoch:[74], loss:0.161953, acc:0.921276\n","epoch:[75], loss:0.159380, acc:0.919283\n","epoch:[76], loss:0.159291, acc:0.917788\n","epoch:[77], loss:0.159322, acc:0.918286\n","epoch:[78], loss:0.158531, acc:0.919781\n","epoch:[79], loss:0.156158, acc:0.914300\n","epoch:[80], loss:0.158185, acc:0.918286\n","epoch:[81], loss:0.158100, acc:0.920777\n","epoch:[82], loss:0.156284, acc:0.921774\n","epoch:[83], loss:0.153568, acc:0.918286\n","epoch:[84], loss:0.154117, acc:0.919781\n","epoch:[85], loss:0.155627, acc:0.921276\n","epoch:[86], loss:0.153217, acc:0.921276\n","epoch:[87], loss:0.154475, acc:0.921276\n","epoch:[88], loss:0.152112, acc:0.921276\n","epoch:[89], loss:0.153307, acc:0.922272\n","epoch:[90], loss:0.150554, acc:0.919283\n","epoch:[91], loss:0.152085, acc:0.921276\n","epoch:[92], loss:0.150611, acc:0.921774\n","epoch:[93], loss:0.150175, acc:0.921774\n","epoch:[94], loss:0.149440, acc:0.921276\n","epoch:[95], loss:0.150271, acc:0.920279\n","epoch:[96], loss:0.147618, acc:0.921774\n","epoch:[97], loss:0.149065, acc:0.924265\n","epoch:[98], loss:0.147344, acc:0.922272\n","epoch:[99], loss:0.146767, acc:0.921774\n","epoch:[100], loss:0.146120, acc:0.921276\n","epoch:[101], loss:0.147401, acc:0.920777\n","epoch:[102], loss:0.145836, acc:0.923269\n","epoch:[103], loss:0.145127, acc:0.918286\n","epoch:[104], loss:0.144195, acc:0.921774\n","epoch:[105], loss:0.144512, acc:0.921276\n","epoch:[106], loss:0.143641, acc:0.921276\n","epoch:[107], loss:0.143599, acc:0.920777\n","epoch:[108], loss:0.142428, acc:0.920777\n","epoch:[109], loss:0.143265, acc:0.923269\n","epoch:[110], loss:0.142403, acc:0.920777\n","epoch:[111], loss:0.141049, acc:0.922770\n","epoch:[112], loss:0.140244, acc:0.923269\n","epoch:[113], loss:0.140177, acc:0.923269\n","epoch:[114], loss:0.140578, acc:0.924265\n","epoch:[115], loss:0.139505, acc:0.923767\n","epoch:[116], loss:0.138422, acc:0.921774\n","epoch:[117], loss:0.138599, acc:0.922770\n","epoch:[118], loss:0.137550, acc:0.922770\n","epoch:[119], loss:0.137086, acc:0.922770\n","epoch:[120], loss:0.136652, acc:0.922272\n","epoch:[121], loss:0.136049, acc:0.922770\n","epoch:[122], loss:0.136098, acc:0.922272\n","epoch:[123], loss:0.135429, acc:0.922272\n","epoch:[124], loss:0.134869, acc:0.924265\n","epoch:[125], loss:0.134326, acc:0.923269\n","epoch:[126], loss:0.135540, acc:0.922272\n","epoch:[127], loss:0.134143, acc:0.924265\n","epoch:[128], loss:0.133505, acc:0.921276\n","epoch:[129], loss:0.133354, acc:0.923767\n","epoch:[130], loss:0.132174, acc:0.923269\n","epoch:[131], loss:0.132259, acc:0.924763\n","epoch:[132], loss:0.131956, acc:0.922770\n","epoch:[133], loss:0.131593, acc:0.923767\n","epoch:[134], loss:0.130215, acc:0.923767\n","epoch:[135], loss:0.130192, acc:0.925262\n","epoch:[136], loss:0.131147, acc:0.924265\n","epoch:[137], loss:0.129960, acc:0.923767\n","epoch:[138], loss:0.128515, acc:0.924265\n","epoch:[139], loss:0.129168, acc:0.923269\n","epoch:[140], loss:0.129128, acc:0.921774\n","epoch:[141], loss:0.128217, acc:0.925262\n","epoch:[142], loss:0.127968, acc:0.924265\n","epoch:[143], loss:0.127413, acc:0.924265\n","epoch:[144], loss:0.126693, acc:0.924265\n","epoch:[145], loss:0.127013, acc:0.925262\n","epoch:[146], loss:0.126137, acc:0.924265\n","epoch:[147], loss:0.125347, acc:0.922770\n","epoch:[148], loss:0.125173, acc:0.924265\n","epoch:[149], loss:0.125064, acc:0.923767\n","epoch:[150], loss:0.125550, acc:0.923269\n","epoch:[151], loss:0.124342, acc:0.924265\n","epoch:[152], loss:0.123460, acc:0.924763\n","epoch:[153], loss:0.124411, acc:0.923767\n","epoch:[154], loss:0.124599, acc:0.923767\n","epoch:[155], loss:0.123742, acc:0.924763\n","epoch:[156], loss:0.122690, acc:0.924265\n","epoch:[157], loss:0.121964, acc:0.924265\n","epoch:[158], loss:0.121249, acc:0.925262\n","epoch:[159], loss:0.121725, acc:0.926258\n","epoch:[160], loss:0.121581, acc:0.924763\n","epoch:[161], loss:0.121016, acc:0.924763\n","epoch:[162], loss:0.120205, acc:0.923767\n","epoch:[163], loss:0.119272, acc:0.924763\n","epoch:[164], loss:0.119056, acc:0.925262\n","epoch:[165], loss:0.119191, acc:0.922770\n","epoch:[166], loss:0.118887, acc:0.926258\n","epoch:[167], loss:0.119009, acc:0.924265\n","epoch:[168], loss:0.117673, acc:0.925262\n","epoch:[169], loss:0.117695, acc:0.925262\n","epoch:[170], loss:0.118250, acc:0.924265\n","epoch:[171], loss:0.117312, acc:0.924763\n","epoch:[172], loss:0.116616, acc:0.923767\n","epoch:[173], loss:0.116482, acc:0.924265\n","epoch:[174], loss:0.116349, acc:0.925262\n","epoch:[175], loss:0.115322, acc:0.925262\n","epoch:[176], loss:0.114829, acc:0.926756\n","epoch:[177], loss:0.114717, acc:0.925760\n","epoch:[178], loss:0.114813, acc:0.927753\n","epoch:[179], loss:0.113706, acc:0.923767\n","epoch:[180], loss:0.113186, acc:0.922272\n","epoch:[181], loss:0.113290, acc:0.923767\n","epoch:[182], loss:0.113035, acc:0.925262\n","epoch:[183], loss:0.112791, acc:0.924763\n","epoch:[184], loss:0.113338, acc:0.923269\n","epoch:[185], loss:0.112564, acc:0.924265\n","epoch:[186], loss:0.112509, acc:0.924763\n","epoch:[187], loss:0.111625, acc:0.924265\n","epoch:[188], loss:0.112383, acc:0.923269\n","epoch:[189], loss:0.110158, acc:0.922770\n","epoch:[190], loss:0.111203, acc:0.923767\n","epoch:[191], loss:0.110863, acc:0.924763\n","epoch:[192], loss:0.110635, acc:0.925760\n","epoch:[193], loss:0.109143, acc:0.924265\n","epoch:[194], loss:0.110380, acc:0.925262\n","epoch:[195], loss:0.109892, acc:0.924763\n","epoch:[196], loss:0.108987, acc:0.925262\n","epoch:[197], loss:0.108537, acc:0.925262\n","epoch:[198], loss:0.108627, acc:0.926258\n","epoch:[199], loss:0.108145, acc:0.926756\n"]}]},{"cell_type":"markdown","source":["**server niid train**"],"metadata":{"id":"7Xmr0Ufk_oCM"}},{"cell_type":"code","source":["net = nn.ModuleDict()\n","net[\"extractor\"] = Extractor()          \n","net[\"classifier\"] = Classifier()    \n","net = net.to(device)\n","frozen_net(net, [\"extractor\", \"classifier\"], True)\n","E_optimizer = optim.Adam(get_params(net, [\"extractor\"]), lr=3e-4, weight_decay=1e-4)\n","CE_criterion = nn.CrossEntropyLoss().to(device)\n","\n","C_checkpoint = torch.load(\"./checkpoint/client_classifier.pkl\", map_location=torch.device('cpu'))\n","net[\"classifier\"].load_state_dict(C_checkpoint)\n","\n","for epoch in range(200):\n","    # train\n","    frozen_net(net, [\"extractor\"], False)\n","    losses, batch = 0., 0\n","    for x, y in server_niid_trainloader:\n","        x = x.to(device)\n","        y = y.to(device)\n","        \n","        E_optimizer.zero_grad()\n","        E = net[\"extractor\"](x)\n","        EC = net[\"classifier\"](E)\n","        loss = CE_criterion(EC, y)\n","        loss.backward()\n","        E_optimizer.step()\n","\n","        losses += loss.item()\n","        batch += 1\n","    avg_loss = losses / batch\n","    frozen_net(net, [\"extractor\"], True)\n","    \n","\n","    # test\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","        for x, y in server_niid_testloader:\n","            x = x.to(device)\n","            y = y.to(device)\n","\n","            E = net[\"extractor\"](x)\n","            EC = net[\"classifier\"](E)\n","\n","            correct += torch.sum((torch.argmax(EC, dim=1) == y).float()).item()\n","            total += x.size(0)\n","    acc = correct / total\n","\n","    print(\"epoch:[%2d], loss:%2.6f, acc:%2.6f\"%(epoch, avg_loss, acc))\n","\n","torch.save(net[\"extractor\"].state_dict(), \"./checkpoint/server_niid_extractor.pkl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Yvtf4Il_qRc","executionInfo":{"status":"ok","timestamp":1640318011607,"user_tz":-480,"elapsed":873610,"user":{"displayName":"吴岳洲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10140082103242733864"}},"outputId":"469d7d8d-6b5f-4eb2-e055-020afd99cb8b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:[ 0], loss:2.923146, acc:0.102800\n","epoch:[ 1], loss:2.366540, acc:0.269000\n","epoch:[ 2], loss:2.021826, acc:0.415200\n","epoch:[ 3], loss:1.766971, acc:0.456600\n","epoch:[ 4], loss:1.615860, acc:0.499300\n","epoch:[ 5], loss:1.512170, acc:0.530300\n","epoch:[ 6], loss:1.432566, acc:0.553800\n","epoch:[ 7], loss:1.365628, acc:0.580100\n","epoch:[ 8], loss:1.307032, acc:0.608700\n","epoch:[ 9], loss:1.252640, acc:0.629900\n","epoch:[10], loss:1.217624, acc:0.635600\n","epoch:[11], loss:1.166871, acc:0.656000\n","epoch:[12], loss:1.129023, acc:0.657900\n","epoch:[13], loss:1.093955, acc:0.684400\n","epoch:[14], loss:1.062051, acc:0.694800\n","epoch:[15], loss:1.026839, acc:0.699000\n","epoch:[16], loss:1.000147, acc:0.707600\n","epoch:[17], loss:0.969532, acc:0.714100\n","epoch:[18], loss:0.942313, acc:0.725000\n","epoch:[19], loss:0.914461, acc:0.730300\n","epoch:[20], loss:0.891187, acc:0.749800\n","epoch:[21], loss:0.866532, acc:0.758900\n","epoch:[22], loss:0.839773, acc:0.763300\n","epoch:[23], loss:0.815734, acc:0.770000\n","epoch:[24], loss:0.798444, acc:0.778700\n","epoch:[25], loss:0.775596, acc:0.782700\n","epoch:[26], loss:0.759035, acc:0.786700\n","epoch:[27], loss:0.746162, acc:0.795600\n","epoch:[28], loss:0.721817, acc:0.797900\n","epoch:[29], loss:0.707696, acc:0.805200\n","epoch:[30], loss:0.688376, acc:0.802900\n","epoch:[31], loss:0.674108, acc:0.812900\n","epoch:[32], loss:0.660502, acc:0.816300\n","epoch:[33], loss:0.645789, acc:0.810100\n","epoch:[34], loss:0.638064, acc:0.821800\n","epoch:[35], loss:0.623608, acc:0.824300\n","epoch:[36], loss:0.617336, acc:0.829200\n","epoch:[37], loss:0.598165, acc:0.831400\n","epoch:[38], loss:0.589302, acc:0.836100\n","epoch:[39], loss:0.580599, acc:0.833200\n","epoch:[40], loss:0.569974, acc:0.843800\n","epoch:[41], loss:0.562688, acc:0.838300\n","epoch:[42], loss:0.552645, acc:0.844100\n","epoch:[43], loss:0.543253, acc:0.845700\n","epoch:[44], loss:0.534810, acc:0.851200\n","epoch:[45], loss:0.529061, acc:0.851800\n","epoch:[46], loss:0.519637, acc:0.852300\n","epoch:[47], loss:0.513341, acc:0.854700\n","epoch:[48], loss:0.508918, acc:0.852500\n","epoch:[49], loss:0.501135, acc:0.860900\n","epoch:[50], loss:0.495568, acc:0.855300\n","epoch:[51], loss:0.489578, acc:0.850700\n","epoch:[52], loss:0.487120, acc:0.862800\n","epoch:[53], loss:0.478797, acc:0.862500\n","epoch:[54], loss:0.475278, acc:0.866500\n","epoch:[55], loss:0.467578, acc:0.867500\n","epoch:[56], loss:0.463750, acc:0.860200\n","epoch:[57], loss:0.457752, acc:0.866500\n","epoch:[58], loss:0.454408, acc:0.868000\n","epoch:[59], loss:0.449835, acc:0.871600\n","epoch:[60], loss:0.443069, acc:0.869000\n","epoch:[61], loss:0.442828, acc:0.875500\n","epoch:[62], loss:0.435368, acc:0.875300\n","epoch:[63], loss:0.430714, acc:0.875300\n","epoch:[64], loss:0.428356, acc:0.874400\n","epoch:[65], loss:0.424564, acc:0.878600\n","epoch:[66], loss:0.419613, acc:0.875700\n","epoch:[67], loss:0.416417, acc:0.877300\n","epoch:[68], loss:0.419620, acc:0.875700\n","epoch:[69], loss:0.410092, acc:0.879100\n","epoch:[70], loss:0.409783, acc:0.877500\n","epoch:[71], loss:0.402157, acc:0.880600\n","epoch:[72], loss:0.400229, acc:0.881700\n","epoch:[73], loss:0.398382, acc:0.878400\n","epoch:[74], loss:0.395676, acc:0.883600\n","epoch:[75], loss:0.392234, acc:0.884900\n","epoch:[76], loss:0.387754, acc:0.882600\n","epoch:[77], loss:0.384735, acc:0.878500\n","epoch:[78], loss:0.382862, acc:0.885000\n","epoch:[79], loss:0.378640, acc:0.885700\n","epoch:[80], loss:0.375986, acc:0.883400\n","epoch:[81], loss:0.375480, acc:0.884700\n","epoch:[82], loss:0.371224, acc:0.886700\n","epoch:[83], loss:0.369436, acc:0.887500\n","epoch:[84], loss:0.366035, acc:0.881900\n","epoch:[85], loss:0.365018, acc:0.888000\n","epoch:[86], loss:0.363605, acc:0.886800\n","epoch:[87], loss:0.360976, acc:0.889700\n","epoch:[88], loss:0.358689, acc:0.889400\n","epoch:[89], loss:0.355138, acc:0.891800\n","epoch:[90], loss:0.352122, acc:0.890200\n","epoch:[91], loss:0.350484, acc:0.891900\n","epoch:[92], loss:0.348689, acc:0.892100\n","epoch:[93], loss:0.347271, acc:0.890000\n","epoch:[94], loss:0.344969, acc:0.892200\n","epoch:[95], loss:0.344540, acc:0.890500\n","epoch:[96], loss:0.340317, acc:0.894300\n","epoch:[97], loss:0.341460, acc:0.881000\n","epoch:[98], loss:0.336569, acc:0.889700\n","epoch:[99], loss:0.335515, acc:0.895100\n","epoch:[100], loss:0.335689, acc:0.893300\n","epoch:[101], loss:0.331916, acc:0.894900\n","epoch:[102], loss:0.331374, acc:0.897800\n","epoch:[103], loss:0.328043, acc:0.898000\n","epoch:[104], loss:0.327697, acc:0.894800\n","epoch:[105], loss:0.322920, acc:0.896300\n","epoch:[106], loss:0.323942, acc:0.895700\n","epoch:[107], loss:0.319609, acc:0.898500\n","epoch:[108], loss:0.318155, acc:0.900000\n","epoch:[109], loss:0.315451, acc:0.887500\n","epoch:[110], loss:0.317633, acc:0.899000\n","epoch:[111], loss:0.316113, acc:0.900500\n","epoch:[112], loss:0.313316, acc:0.894600\n","epoch:[113], loss:0.310501, acc:0.898100\n","epoch:[114], loss:0.308887, acc:0.900500\n","epoch:[115], loss:0.313574, acc:0.901100\n","epoch:[116], loss:0.311256, acc:0.901100\n","epoch:[117], loss:0.306327, acc:0.897800\n","epoch:[118], loss:0.306073, acc:0.902700\n","epoch:[119], loss:0.303517, acc:0.902600\n","epoch:[120], loss:0.302251, acc:0.901400\n","epoch:[121], loss:0.301853, acc:0.904000\n","epoch:[122], loss:0.297529, acc:0.896900\n","epoch:[123], loss:0.297475, acc:0.902100\n","epoch:[124], loss:0.296867, acc:0.903800\n","epoch:[125], loss:0.296526, acc:0.904700\n","epoch:[126], loss:0.293159, acc:0.900800\n","epoch:[127], loss:0.293763, acc:0.902900\n","epoch:[128], loss:0.291942, acc:0.905700\n","epoch:[129], loss:0.290939, acc:0.903800\n","epoch:[130], loss:0.290061, acc:0.903200\n","epoch:[131], loss:0.289123, acc:0.904300\n","epoch:[132], loss:0.290020, acc:0.905100\n","epoch:[133], loss:0.283654, acc:0.907200\n","epoch:[134], loss:0.285422, acc:0.904400\n","epoch:[135], loss:0.283941, acc:0.906100\n","epoch:[136], loss:0.281560, acc:0.906200\n","epoch:[137], loss:0.281048, acc:0.907200\n","epoch:[138], loss:0.281309, acc:0.904600\n","epoch:[139], loss:0.281268, acc:0.906500\n","epoch:[140], loss:0.277352, acc:0.907000\n","epoch:[141], loss:0.276823, acc:0.909200\n","epoch:[142], loss:0.275440, acc:0.906000\n","epoch:[143], loss:0.277286, acc:0.909500\n","epoch:[144], loss:0.276066, acc:0.904200\n","epoch:[145], loss:0.271868, acc:0.910000\n","epoch:[146], loss:0.271894, acc:0.909800\n","epoch:[147], loss:0.268373, acc:0.910700\n","epoch:[148], loss:0.268842, acc:0.911100\n","epoch:[149], loss:0.269432, acc:0.910000\n","epoch:[150], loss:0.269894, acc:0.911000\n","epoch:[151], loss:0.265027, acc:0.909600\n","epoch:[152], loss:0.266179, acc:0.908900\n","epoch:[153], loss:0.267205, acc:0.910200\n","epoch:[154], loss:0.265456, acc:0.910000\n","epoch:[155], loss:0.262095, acc:0.912000\n","epoch:[156], loss:0.262712, acc:0.909100\n","epoch:[157], loss:0.261789, acc:0.912500\n","epoch:[158], loss:0.260255, acc:0.911400\n","epoch:[159], loss:0.261748, acc:0.911000\n","epoch:[160], loss:0.259141, acc:0.912700\n","epoch:[161], loss:0.256372, acc:0.913000\n","epoch:[162], loss:0.255717, acc:0.912800\n","epoch:[163], loss:0.256390, acc:0.913100\n","epoch:[164], loss:0.255548, acc:0.911000\n","epoch:[165], loss:0.254084, acc:0.913900\n","epoch:[166], loss:0.253971, acc:0.912800\n","epoch:[167], loss:0.253297, acc:0.914500\n","epoch:[168], loss:0.249962, acc:0.914700\n","epoch:[169], loss:0.252406, acc:0.912200\n","epoch:[170], loss:0.250765, acc:0.914000\n","epoch:[171], loss:0.248089, acc:0.907300\n","epoch:[172], loss:0.247991, acc:0.915300\n","epoch:[173], loss:0.248236, acc:0.916200\n","epoch:[174], loss:0.246741, acc:0.913300\n","epoch:[175], loss:0.246162, acc:0.910200\n","epoch:[176], loss:0.245675, acc:0.916200\n","epoch:[177], loss:0.245597, acc:0.914500\n","epoch:[178], loss:0.244822, acc:0.914100\n","epoch:[179], loss:0.242771, acc:0.914900\n","epoch:[180], loss:0.242065, acc:0.912900\n","epoch:[181], loss:0.243514, acc:0.914300\n","epoch:[182], loss:0.241793, acc:0.916800\n","epoch:[183], loss:0.241906, acc:0.916300\n","epoch:[184], loss:0.237877, acc:0.915400\n","epoch:[185], loss:0.237838, acc:0.917700\n","epoch:[186], loss:0.239762, acc:0.917900\n","epoch:[187], loss:0.240129, acc:0.917100\n","epoch:[188], loss:0.237036, acc:0.915900\n","epoch:[189], loss:0.237723, acc:0.916200\n","epoch:[190], loss:0.237947, acc:0.917800\n","epoch:[191], loss:0.235965, acc:0.916500\n","epoch:[192], loss:0.234265, acc:0.917500\n","epoch:[193], loss:0.232438, acc:0.918800\n","epoch:[194], loss:0.232253, acc:0.917600\n","epoch:[195], loss:0.232465, acc:0.918000\n","epoch:[196], loss:0.230213, acc:0.918100\n","epoch:[197], loss:0.230974, acc:0.918900\n","epoch:[198], loss:0.231362, acc:0.917600\n","epoch:[199], loss:0.230490, acc:0.919300\n"]}]},{"cell_type":"markdown","source":["**GAN train**"],"metadata":{"id":"xsQF1cMbQ8_D"}},{"cell_type":"code","source":["net = nn.ModuleDict()\n","net[\"extractor\"] = Extractor()          \n","net[\"classifier\"] = Classifier()\n","net[\"generator\"] = Generator()\n","net[\"discriminator\"] = Discriminator()\n","net = net.to(device)\n","frozen_net(net, [\"extractor\", \"classifier\", \"generator\", \"discriminator\"], True)\n","\n","D_optimizer = optim.Adam(get_params(net, [\"discriminator\"]), lr=2e-4, betas=(0.5, 0.999))\n","G_optimizer = optim.Adam(get_params(net, [\"generator\"]), lr=2e-4, betas=(0.5, 0.999))\n","BCE_criterion = nn.BCELoss().to(device)\n","\n","E_checkpoint = torch.load(\"./checkpoint/client_extractor.pkl\", map_location=torch.device('cpu'))\n","net[\"extractor\"].load_state_dict(E_checkpoint)\n","C_checkpoint = torch.load(\"./checkpoint/client_classifier.pkl\", map_location=torch.device('cpu'))\n","net[\"classifier\"].load_state_dict(C_checkpoint)\n","\n","\n","def discriminator_loss(E, G, y):\n","    ones = torch.ones((E.size(0), 1)).to(device)\n","    ED = net[\"discriminator\"](E.detach(), y)\n","    ED_loss = BCE_criterion(ED, ones)\n","\n","    zeros = torch.zeros((G.size(0), 1)).to(device)\n","    GD = net[\"discriminator\"](G.detach(), y)\n","    GD_loss = BCE_criterion(GD, zeros)\n","    return ED_loss + GD_loss\n","\n","\n","def generator_loss(G, y):\n","    ones = torch.ones((G.size(0), 1)).to(device)\n","    GD = net[\"discriminator\"](G, y)\n","    G_loss = BCE_criterion(GD, ones)\n","    return G_loss\n","\n","\n","for epoch in range(200):\n","    # train\n","    frozen_net(net, [\"generator\", \"discriminator\"], False)\n","\n","    D_losses, G_losses = [], []\n","    for batch, (x, y) in enumerate(client_trainloader):\n","        x = x.to(device)\n","        y = y.to(device)\n","        z = torch.randn(x.size(0), 100, 1, 1).to(device)\n","\n","        with torch.no_grad():\n","            E = net[\"extractor\"](x)\n","        G = net[\"generator\"](z, y)\n","\n","        # update D\n","        D_optimizer.zero_grad()\n","        D_loss = discriminator_loss(E, G, y)\n","        D_loss.backward()\n","        D_optimizer.step()\n","        D_losses.append(D_loss.item())\n","\n","        # update G\n","        G_optimizer.zero_grad()\n","        G_loss = generator_loss(G, y)\n","        G_loss.backward()\n","        G_optimizer.step()\n","        G_losses.append(G_loss.item())\n","    \n","    frozen_net(net, [\"generator\", \"discriminator\"], True)\n","\n","    # test\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","        for x, y in client_testloader:\n","            y = y.to(device)\n","            z = torch.randn(x.size(0), 100, 1, 1).to(device)\n","\n","            G = net[\"generator\"](z, y)\n","            GC = net[\"classifier\"](G)\n","\n","            correct += torch.sum((torch.argmax(GC, dim=1) == y).float()).item()\n","            total += x.size(0)\n","    acc = correct / total\n","\n","    print(\"epoch:[%2d], D_loss:%2.6f, G_loss:%2.6f, acc:%2.6f\"\n","        %(epoch, np.mean(D_losses), np.mean(G_losses), acc))\n","\n","    if (epoch+1) % 10 == 0:\n","        torch.save(net[\"generator\"].state_dict(), \"./checkpoint/client_generator.pkl\")\n","        torch.save(net[\"discriminator\"].state_dict(), \"./checkpoint/client_discriminator.pkl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0mcjqTXxQ_Y9","executionInfo":{"status":"ok","timestamp":1640322381210,"user_tz":-480,"elapsed":4369606,"user":{"displayName":"吴岳洲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10140082103242733864"}},"outputId":"ce3b04b6-2a39-4a77-e228-2cfdbf2b396c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:[ 0], D_loss:0.344608, G_loss:3.037637, acc:0.098655\n","epoch:[ 1], D_loss:0.118900, G_loss:4.418280, acc:0.369208\n","epoch:[ 2], D_loss:0.299082, G_loss:4.339326, acc:0.712008\n","epoch:[ 3], D_loss:0.533858, G_loss:3.677392, acc:0.862481\n","epoch:[ 4], D_loss:0.655734, G_loss:3.264099, acc:0.949178\n","epoch:[ 5], D_loss:0.775410, G_loss:2.701448, acc:0.979571\n","epoch:[ 6], D_loss:0.815621, G_loss:2.569082, acc:0.974091\n","epoch:[ 7], D_loss:0.853543, G_loss:2.414339, acc:0.975087\n","epoch:[ 8], D_loss:0.767617, G_loss:2.452268, acc:0.967613\n","epoch:[ 9], D_loss:0.799125, G_loss:2.517888, acc:0.966119\n","epoch:[10], D_loss:0.790975, G_loss:2.487391, acc:0.972098\n","epoch:[11], D_loss:0.793575, G_loss:2.582605, acc:0.973592\n","epoch:[12], D_loss:0.714652, G_loss:2.595330, acc:0.971101\n","epoch:[13], D_loss:0.732304, G_loss:2.638033, acc:0.964126\n","epoch:[14], D_loss:0.680403, G_loss:2.725231, acc:0.965122\n","epoch:[15], D_loss:0.695786, G_loss:2.843229, acc:0.972596\n","epoch:[16], D_loss:0.722535, G_loss:2.779969, acc:0.970603\n","epoch:[17], D_loss:0.647502, G_loss:2.858736, acc:0.979571\n","epoch:[18], D_loss:0.665948, G_loss:2.920367, acc:0.978575\n","epoch:[19], D_loss:0.652949, G_loss:3.010251, acc:0.979073\n","epoch:[20], D_loss:0.638716, G_loss:3.039167, acc:0.982063\n","epoch:[21], D_loss:0.608248, G_loss:3.070872, acc:0.980568\n","epoch:[22], D_loss:0.686637, G_loss:2.917149, acc:0.981066\n","epoch:[23], D_loss:0.715067, G_loss:2.979727, acc:0.984056\n","epoch:[24], D_loss:0.632773, G_loss:3.063096, acc:0.979073\n","epoch:[25], D_loss:0.587790, G_loss:3.118014, acc:0.981565\n","epoch:[26], D_loss:0.567335, G_loss:3.256695, acc:0.981565\n","epoch:[27], D_loss:0.680850, G_loss:3.156604, acc:0.983558\n","epoch:[28], D_loss:0.571928, G_loss:3.176520, acc:0.985551\n","epoch:[29], D_loss:0.648038, G_loss:3.201172, acc:0.984056\n","epoch:[30], D_loss:0.625700, G_loss:3.216018, acc:0.979571\n","epoch:[31], D_loss:0.543815, G_loss:3.321835, acc:0.981066\n","epoch:[32], D_loss:0.602713, G_loss:3.423163, acc:0.989038\n","epoch:[33], D_loss:0.608839, G_loss:3.317116, acc:0.984554\n","epoch:[34], D_loss:0.540425, G_loss:3.455719, acc:0.986049\n","epoch:[35], D_loss:0.576005, G_loss:3.435040, acc:0.982561\n","epoch:[36], D_loss:0.581432, G_loss:3.408464, acc:0.976582\n","epoch:[37], D_loss:0.599935, G_loss:3.456061, acc:0.984554\n","epoch:[38], D_loss:0.536219, G_loss:3.383053, acc:0.976084\n","epoch:[39], D_loss:0.550355, G_loss:3.531106, acc:0.989038\n","epoch:[40], D_loss:0.568948, G_loss:3.586391, acc:0.989038\n","epoch:[41], D_loss:0.487098, G_loss:3.586248, acc:0.985052\n","epoch:[42], D_loss:0.553638, G_loss:3.579567, acc:0.988042\n","epoch:[43], D_loss:0.555156, G_loss:3.557754, acc:0.984056\n","epoch:[44], D_loss:0.583121, G_loss:3.495421, acc:0.989038\n","epoch:[45], D_loss:0.569364, G_loss:3.514133, acc:0.981565\n","epoch:[46], D_loss:0.581112, G_loss:3.396627, acc:0.989537\n","epoch:[47], D_loss:0.538408, G_loss:3.571375, acc:0.990533\n","epoch:[48], D_loss:0.538134, G_loss:3.612355, acc:0.988540\n","epoch:[49], D_loss:0.501076, G_loss:3.703701, acc:0.990035\n","epoch:[50], D_loss:0.550172, G_loss:3.725186, acc:0.985551\n","epoch:[51], D_loss:0.466016, G_loss:3.618583, acc:0.978077\n","epoch:[52], D_loss:0.543564, G_loss:3.720186, acc:0.987045\n","epoch:[53], D_loss:0.499902, G_loss:3.716954, acc:0.991530\n","epoch:[54], D_loss:0.479916, G_loss:3.819529, acc:0.986049\n","epoch:[55], D_loss:0.498003, G_loss:3.826961, acc:0.989038\n","epoch:[56], D_loss:0.513883, G_loss:3.788222, acc:0.992526\n","epoch:[57], D_loss:0.512428, G_loss:3.819624, acc:0.983558\n","epoch:[58], D_loss:0.454321, G_loss:3.812321, acc:0.977578\n","epoch:[59], D_loss:0.513382, G_loss:3.870846, acc:0.987544\n","epoch:[60], D_loss:0.511304, G_loss:3.834907, acc:0.988540\n","epoch:[61], D_loss:0.554672, G_loss:3.836198, acc:0.992526\n","epoch:[62], D_loss:0.429843, G_loss:3.809747, acc:0.987045\n","epoch:[63], D_loss:0.455579, G_loss:3.818591, acc:0.984056\n","epoch:[64], D_loss:0.422959, G_loss:4.092410, acc:0.981565\n","epoch:[65], D_loss:0.500562, G_loss:4.032327, acc:0.983059\n","epoch:[66], D_loss:0.452538, G_loss:3.902581, acc:0.984554\n","epoch:[67], D_loss:0.500738, G_loss:4.026261, acc:0.985052\n","epoch:[68], D_loss:0.435681, G_loss:4.087040, acc:0.976582\n","epoch:[69], D_loss:0.381209, G_loss:4.245514, acc:0.988540\n","epoch:[70], D_loss:0.455315, G_loss:4.148276, acc:0.993523\n","epoch:[71], D_loss:0.383793, G_loss:4.189885, acc:0.990035\n","epoch:[72], D_loss:0.464892, G_loss:4.151028, acc:0.990533\n","epoch:[73], D_loss:0.452120, G_loss:4.224998, acc:0.987544\n","epoch:[74], D_loss:0.457047, G_loss:4.154929, acc:0.988540\n","epoch:[75], D_loss:0.416223, G_loss:4.162644, acc:0.993523\n","epoch:[76], D_loss:0.401205, G_loss:4.200205, acc:0.993523\n","epoch:[77], D_loss:0.355702, G_loss:4.439752, acc:0.985551\n","epoch:[78], D_loss:0.451829, G_loss:4.382079, acc:0.987544\n","epoch:[79], D_loss:0.428712, G_loss:4.331474, acc:0.991530\n","epoch:[80], D_loss:0.426954, G_loss:4.217052, acc:0.987045\n","epoch:[81], D_loss:0.462592, G_loss:4.170939, acc:0.983059\n","epoch:[82], D_loss:0.388437, G_loss:4.205722, acc:0.986049\n","epoch:[83], D_loss:0.347987, G_loss:4.354945, acc:0.984056\n","epoch:[84], D_loss:0.337496, G_loss:4.463517, acc:0.989537\n","epoch:[85], D_loss:0.385165, G_loss:4.546087, acc:0.990035\n","epoch:[86], D_loss:0.375633, G_loss:4.499703, acc:0.990533\n","epoch:[87], D_loss:0.407498, G_loss:4.515906, acc:0.990533\n","epoch:[88], D_loss:0.384581, G_loss:4.501634, acc:0.990533\n","epoch:[89], D_loss:0.421258, G_loss:4.446742, acc:0.986049\n","epoch:[90], D_loss:0.483020, G_loss:4.408463, acc:0.992028\n","epoch:[91], D_loss:0.329019, G_loss:4.505480, acc:0.988540\n","epoch:[92], D_loss:0.380427, G_loss:4.576526, acc:0.993024\n","epoch:[93], D_loss:0.350462, G_loss:4.566361, acc:0.989537\n","epoch:[94], D_loss:0.438092, G_loss:4.452137, acc:0.989038\n","epoch:[95], D_loss:0.386076, G_loss:4.396354, acc:0.991530\n","epoch:[96], D_loss:0.382940, G_loss:4.584447, acc:0.986049\n","epoch:[97], D_loss:0.321991, G_loss:4.612122, acc:0.983558\n","epoch:[98], D_loss:0.304980, G_loss:4.788634, acc:0.984554\n","epoch:[99], D_loss:0.472345, G_loss:4.746722, acc:0.984056\n","epoch:[100], D_loss:0.400163, G_loss:4.525795, acc:0.986049\n","epoch:[101], D_loss:0.368713, G_loss:4.668946, acc:0.991530\n","epoch:[102], D_loss:0.336729, G_loss:4.639734, acc:0.990533\n","epoch:[103], D_loss:0.331696, G_loss:4.848863, acc:0.994021\n","epoch:[104], D_loss:0.429422, G_loss:4.760526, acc:0.990533\n","epoch:[105], D_loss:0.299268, G_loss:4.662757, acc:0.993523\n","epoch:[106], D_loss:0.296959, G_loss:4.782631, acc:0.991031\n","epoch:[107], D_loss:0.405001, G_loss:4.835606, acc:0.991031\n","epoch:[108], D_loss:0.329549, G_loss:4.663554, acc:0.992028\n","epoch:[109], D_loss:0.269502, G_loss:4.887763, acc:0.987045\n","epoch:[110], D_loss:0.393041, G_loss:4.977209, acc:0.988042\n","epoch:[111], D_loss:0.313398, G_loss:4.834305, acc:0.987045\n","epoch:[112], D_loss:0.286005, G_loss:4.843050, acc:0.987544\n","epoch:[113], D_loss:0.281026, G_loss:4.909829, acc:0.994021\n","epoch:[114], D_loss:0.358687, G_loss:5.035427, acc:0.981066\n","epoch:[115], D_loss:0.325606, G_loss:4.993762, acc:0.984056\n","epoch:[116], D_loss:0.320343, G_loss:4.956113, acc:0.986049\n","epoch:[117], D_loss:0.394029, G_loss:5.010139, acc:0.990533\n","epoch:[118], D_loss:0.354588, G_loss:4.848258, acc:0.992526\n","epoch:[119], D_loss:0.323557, G_loss:4.866402, acc:0.992028\n","epoch:[120], D_loss:0.288909, G_loss:5.014464, acc:0.989537\n","epoch:[121], D_loss:0.282549, G_loss:5.026975, acc:0.990035\n","epoch:[122], D_loss:0.294378, G_loss:4.972925, acc:0.987544\n","epoch:[123], D_loss:0.284245, G_loss:5.157274, acc:0.990533\n","epoch:[124], D_loss:0.329658, G_loss:5.107598, acc:0.992028\n","epoch:[125], D_loss:0.312585, G_loss:5.113126, acc:0.990035\n","epoch:[126], D_loss:0.306641, G_loss:5.064764, acc:0.988540\n","epoch:[127], D_loss:0.304242, G_loss:5.154033, acc:0.991031\n","epoch:[128], D_loss:0.313536, G_loss:5.177209, acc:0.992526\n","epoch:[129], D_loss:0.299883, G_loss:5.125921, acc:0.992028\n","epoch:[130], D_loss:0.232466, G_loss:5.259582, acc:0.984056\n","epoch:[131], D_loss:0.314296, G_loss:5.172498, acc:0.991031\n","epoch:[132], D_loss:0.229906, G_loss:5.281241, acc:0.994519\n","epoch:[133], D_loss:0.290193, G_loss:5.364844, acc:0.993024\n","epoch:[134], D_loss:0.270142, G_loss:5.402112, acc:0.989537\n","epoch:[135], D_loss:0.357529, G_loss:5.250587, acc:0.985551\n","epoch:[136], D_loss:0.306012, G_loss:5.107755, acc:0.989038\n","epoch:[137], D_loss:0.232208, G_loss:5.368454, acc:0.988540\n","epoch:[138], D_loss:0.224111, G_loss:5.465472, acc:0.995516\n","epoch:[139], D_loss:0.209541, G_loss:5.304509, acc:0.990035\n","epoch:[140], D_loss:0.288417, G_loss:5.665180, acc:0.992526\n","epoch:[141], D_loss:0.352622, G_loss:5.439167, acc:0.993523\n","epoch:[142], D_loss:0.320169, G_loss:5.345605, acc:0.990533\n","epoch:[143], D_loss:0.265659, G_loss:5.267698, acc:0.985052\n","epoch:[144], D_loss:0.241545, G_loss:5.496332, acc:0.989537\n","epoch:[145], D_loss:0.235785, G_loss:5.497461, acc:0.990533\n","epoch:[146], D_loss:0.277364, G_loss:5.513311, acc:0.991031\n","epoch:[147], D_loss:0.236480, G_loss:5.569605, acc:0.992526\n","epoch:[148], D_loss:0.215613, G_loss:5.751352, acc:0.989537\n","epoch:[149], D_loss:0.326874, G_loss:5.490434, acc:0.987544\n","epoch:[150], D_loss:0.263709, G_loss:5.497568, acc:0.992526\n","epoch:[151], D_loss:0.258475, G_loss:5.369451, acc:0.992028\n","epoch:[152], D_loss:0.305025, G_loss:5.356365, acc:0.994021\n","epoch:[153], D_loss:0.288642, G_loss:5.350659, acc:0.994519\n","epoch:[154], D_loss:0.205838, G_loss:5.596158, acc:0.995017\n","epoch:[155], D_loss:0.221125, G_loss:5.747694, acc:0.993523\n","epoch:[156], D_loss:0.199020, G_loss:5.703587, acc:0.996512\n","epoch:[157], D_loss:0.200316, G_loss:5.609427, acc:0.995516\n","epoch:[158], D_loss:0.177633, G_loss:5.843402, acc:0.990533\n","epoch:[159], D_loss:0.322225, G_loss:5.663931, acc:0.981565\n","epoch:[160], D_loss:0.279668, G_loss:5.720850, acc:0.986049\n","epoch:[161], D_loss:0.163349, G_loss:5.706943, acc:0.992526\n","epoch:[162], D_loss:0.202580, G_loss:5.855657, acc:0.995516\n","epoch:[163], D_loss:0.331643, G_loss:5.706308, acc:0.988042\n","epoch:[164], D_loss:0.314425, G_loss:5.568587, acc:0.995017\n","epoch:[165], D_loss:0.227350, G_loss:5.583982, acc:0.993523\n","epoch:[166], D_loss:0.181923, G_loss:5.908321, acc:0.991031\n","epoch:[167], D_loss:0.250624, G_loss:5.788487, acc:0.993024\n","epoch:[168], D_loss:0.199707, G_loss:5.923613, acc:0.989537\n","epoch:[169], D_loss:0.215984, G_loss:6.015650, acc:0.992526\n","epoch:[170], D_loss:0.211077, G_loss:5.984658, acc:0.991031\n","epoch:[171], D_loss:0.174457, G_loss:5.894387, acc:0.992028\n","epoch:[172], D_loss:0.196917, G_loss:6.281976, acc:0.991031\n","epoch:[173], D_loss:0.223909, G_loss:6.285200, acc:0.992028\n","epoch:[174], D_loss:0.186816, G_loss:6.054129, acc:0.990035\n","epoch:[175], D_loss:0.168020, G_loss:6.258229, acc:0.987045\n","epoch:[176], D_loss:0.267795, G_loss:6.073740, acc:0.991031\n","epoch:[177], D_loss:0.269193, G_loss:6.091586, acc:0.994519\n","epoch:[178], D_loss:0.278806, G_loss:5.879217, acc:0.992028\n","epoch:[179], D_loss:0.165615, G_loss:6.030822, acc:0.995516\n","epoch:[180], D_loss:0.230042, G_loss:6.030847, acc:0.992526\n","epoch:[181], D_loss:0.207721, G_loss:6.075307, acc:0.989038\n","epoch:[182], D_loss:0.165139, G_loss:6.119109, acc:0.994021\n","epoch:[183], D_loss:0.190350, G_loss:6.259367, acc:0.992526\n","epoch:[184], D_loss:0.156317, G_loss:6.127663, acc:0.985551\n","epoch:[185], D_loss:0.205077, G_loss:6.318305, acc:0.997010\n","epoch:[186], D_loss:0.163531, G_loss:6.229236, acc:0.991031\n","epoch:[187], D_loss:0.231510, G_loss:6.268695, acc:0.988042\n","epoch:[188], D_loss:0.250334, G_loss:6.129752, acc:0.991530\n","epoch:[189], D_loss:0.236458, G_loss:6.141851, acc:0.993523\n","epoch:[190], D_loss:0.177992, G_loss:6.062889, acc:0.990533\n","epoch:[191], D_loss:0.146522, G_loss:6.190350, acc:0.987045\n","epoch:[192], D_loss:0.174249, G_loss:6.212593, acc:0.992526\n","epoch:[193], D_loss:0.239678, G_loss:6.403663, acc:0.991031\n","epoch:[194], D_loss:0.178318, G_loss:6.258833, acc:0.993024\n","epoch:[195], D_loss:0.193384, G_loss:6.410665, acc:0.994021\n","epoch:[196], D_loss:0.129400, G_loss:6.486812, acc:0.993024\n","epoch:[197], D_loss:0.212744, G_loss:6.253687, acc:0.992526\n","epoch:[198], D_loss:0.321920, G_loss:6.105253, acc:0.994519\n","epoch:[199], D_loss:0.181793, G_loss:6.061414, acc:0.990035\n"]}]},{"cell_type":"markdown","source":["**GAN div train**"],"metadata":{"id":"Nj5bLTAsEguA"}},{"cell_type":"code","source":["net = nn.ModuleDict()\n","net[\"extractor\"] = Extractor()          \n","net[\"classifier\"] = Classifier()\n","net[\"generator\"] = Generator()\n","net[\"discriminator\"] = Discriminator()\n","net = net.to(device)\n","frozen_net(net, [\"extractor\", \"classifier\", \"generator\", \"discriminator\"], True)\n","\n","D_optimizer = optim.Adam(get_params(net, [\"discriminator\"]), lr=2e-4, betas=(0.5, 0.999))\n","G_optimizer = optim.Adam(get_params(net, [\"generator\"]), lr=4e-4, betas=(0.5, 0.999))\n","BCE_criterion = nn.BCELoss().to(device)\n","\n","E_checkpoint = torch.load(\"./checkpoint/client_extractor.pkl\", map_location=torch.device('cpu'))\n","net[\"extractor\"].load_state_dict(E_checkpoint)\n","C_checkpoint = torch.load(\"./checkpoint/client_classifier.pkl\", map_location=torch.device('cpu'))\n","net[\"classifier\"].load_state_dict(C_checkpoint)\n","\n","\n","def diversity_loss(G1, G2, z1, z2):\n","    lz = torch.mean(torch.abs(G2 - G1)) / torch.mean(torch.abs(z2 - z1))\n","    eps = 1 * 1e-5\n","    G_div = 1 / (lz + eps)\n","    return G_div\n","\n","\n","def discriminator_loss(E, G, y):\n","    ones = torch.ones((E.size(0), 1)).to(device)\n","    ED = net[\"discriminator\"](E.detach(), y)\n","    ED_loss = BCE_criterion(ED, ones)\n","\n","    zeros = torch.zeros((G.size(0), 1)).to(device)\n","    GD = net[\"discriminator\"](G.detach(), y)\n","    GD_loss = BCE_criterion(GD, zeros)\n","    return ED_loss + GD_loss\n","\n","\n","def generator_loss(G, y):\n","    ones = torch.ones((G.size(0), 1)).to(device)\n","    GD = net[\"discriminator\"](G, y)\n","    G_loss = BCE_criterion(GD, ones)\n","    return G_loss\n","\n","\n","for epoch in range(200):\n","    # train\n","    frozen_net(net, [\"generator\", \"discriminator\"], False)\n","\n","    D_losses, G_losses, G_divs = [], [], []\n","    for batch, (x, y) in enumerate(client_trainloader):\n","        x = x.to(device)\n","        y = y.to(device)\n","\n","        with torch.no_grad():\n","            E = net[\"extractor\"](x)\n","\n","        # update D\n","        D_optimizer.zero_grad()\n","        z = torch.randn(x.size(0), 100, 1, 1).to(device)\n","        G = net[\"generator\"](z, y)\n","        D_loss = discriminator_loss(E, G, y)\n","\n","        D_loss.backward()\n","        D_optimizer.step()\n","        D_losses.append(D_loss.item())\n","\n","        # update G\n","        if (batch+1)%2 == 0:\n","            G_optimizer.zero_grad()\n","            ys = torch.cat([y,y], 0)\n","            zs = torch.randn(x.size(0)*2, 100, 1, 1).to(device)\n","            Gs = net[\"generator\"](zs, ys)\n","            G_loss = generator_loss(Gs, ys)\n","\n","            z1, z2 = torch.split(zs, x.size(0), 0)\n","            G1, G2 = torch.split(Gs, x.size(0), 0)\n","            G_div = diversity_loss(G1, G2, z1, z2)\n","\n","            (G_loss + G_div).backward()\n","            G_optimizer.step()\n","            G_losses.append(G_loss.item())\n","            G_divs.append(G_div.item())\n","    \n","    frozen_net(net, [\"generator\", \"discriminator\"], True)\n","\n","    # test\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","        for x, y in client_testloader:\n","            y = y.to(device)\n","            z = torch.randn(x.size(0), 100, 1, 1).to(device)\n","\n","            G = net[\"generator\"](z, y)\n","            GC = net[\"classifier\"](G)\n","\n","            correct += torch.sum((torch.argmax(GC, dim=1) == y).float()).item()\n","            total += x.size(0)\n","    acc = correct / total\n","\n","    print(\"epoch:[%2d], D_loss:%2.6f, G_loss:%2.6f, G_div:%2.6f, acc:%2.6f\"\n","        %(epoch, np.mean(D_losses), np.mean(G_losses), np.mean(G_divs), acc))\n","\n","    if (epoch+1) % 10 == 0:\n","        torch.save(net[\"generator\"].state_dict(), \"./checkpoint/client_generator_div.pkl\")\n","        torch.save(net[\"discriminator\"].state_dict(), \"./checkpoint/client_discriminator_div.pkl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rGpwDDm5EjjR","outputId":"3b70e99d-7012-478a-82ba-aa04d535da50","executionInfo":{"status":"ok","timestamp":1640326696036,"user_tz":-480,"elapsed":4314829,"user":{"displayName":"吴岳洲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10140082103242733864"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:[ 0], D_loss:0.259275, G_loss:2.965623, G_div:10.834201, acc:0.118585\n","epoch:[ 1], D_loss:0.050760, G_loss:4.501555, G_div:5.210158, acc:0.199801\n","epoch:[ 2], D_loss:0.119526, G_loss:5.419510, G_div:4.619545, acc:0.282013\n","epoch:[ 3], D_loss:0.197628, G_loss:4.993534, G_div:4.403781, acc:0.456403\n","epoch:[ 4], D_loss:0.398614, G_loss:4.170278, G_div:4.462311, acc:0.651719\n","epoch:[ 5], D_loss:0.514191, G_loss:3.637313, G_div:4.693073, acc:0.753861\n","epoch:[ 6], D_loss:0.613035, G_loss:3.135381, G_div:4.520527, acc:0.839063\n","epoch:[ 7], D_loss:0.594661, G_loss:2.774623, G_div:4.648679, acc:0.894868\n","epoch:[ 8], D_loss:0.656109, G_loss:2.770310, G_div:4.774084, acc:0.918286\n","epoch:[ 9], D_loss:0.617779, G_loss:2.594102, G_div:4.673817, acc:0.920777\n","epoch:[10], D_loss:0.680715, G_loss:2.696926, G_div:4.704286, acc:0.918784\n","epoch:[11], D_loss:0.496789, G_loss:2.788996, G_div:4.745675, acc:0.943199\n","epoch:[12], D_loss:0.592919, G_loss:2.911039, G_div:4.835534, acc:0.920777\n","epoch:[13], D_loss:0.609474, G_loss:2.723920, G_div:4.726285, acc:0.951669\n","epoch:[14], D_loss:0.581631, G_loss:2.636253, G_div:4.741443, acc:0.957150\n","epoch:[15], D_loss:0.596778, G_loss:2.695121, G_div:4.850992, acc:0.951669\n","epoch:[16], D_loss:0.542604, G_loss:3.042264, G_div:4.804814, acc:0.969606\n","epoch:[17], D_loss:0.659933, G_loss:2.776217, G_div:4.793054, acc:0.969606\n","epoch:[18], D_loss:0.588799, G_loss:2.806346, G_div:4.715615, acc:0.959641\n","epoch:[19], D_loss:0.511145, G_loss:2.946940, G_div:4.822669, acc:0.963129\n","epoch:[20], D_loss:0.594259, G_loss:2.816921, G_div:4.867281, acc:0.953164\n","epoch:[21], D_loss:0.598843, G_loss:2.854491, G_div:4.850531, acc:0.957150\n","epoch:[22], D_loss:0.553669, G_loss:2.765732, G_div:4.927917, acc:0.962133\n","epoch:[23], D_loss:0.574889, G_loss:2.831816, G_div:4.883453, acc:0.959143\n","epoch:[24], D_loss:0.556391, G_loss:3.098793, G_div:5.003955, acc:0.965122\n","epoch:[25], D_loss:0.644000, G_loss:2.835108, G_div:4.953218, acc:0.968112\n","epoch:[26], D_loss:0.548722, G_loss:2.735785, G_div:4.850654, acc:0.959641\n","epoch:[27], D_loss:0.598275, G_loss:2.694166, G_div:4.953189, acc:0.971101\n","epoch:[28], D_loss:0.521170, G_loss:2.753843, G_div:4.854347, acc:0.975585\n","epoch:[29], D_loss:0.558275, G_loss:3.064997, G_div:4.740513, acc:0.961136\n","epoch:[30], D_loss:0.525559, G_loss:2.990657, G_div:4.973537, acc:0.967115\n","epoch:[31], D_loss:0.596516, G_loss:2.921581, G_div:4.880160, acc:0.961136\n","epoch:[32], D_loss:0.562665, G_loss:2.775902, G_div:4.899766, acc:0.970603\n","epoch:[33], D_loss:0.544117, G_loss:2.925207, G_div:4.931717, acc:0.977578\n","epoch:[34], D_loss:0.587837, G_loss:2.875069, G_div:4.851381, acc:0.975585\n","epoch:[35], D_loss:0.549727, G_loss:3.068729, G_div:4.887327, acc:0.970603\n","epoch:[36], D_loss:0.466048, G_loss:3.030824, G_div:4.896762, acc:0.968610\n","epoch:[37], D_loss:0.533079, G_loss:2.894674, G_div:4.809765, acc:0.971599\n","epoch:[38], D_loss:0.574216, G_loss:2.876764, G_div:4.975997, acc:0.969606\n","epoch:[39], D_loss:0.538414, G_loss:2.843712, G_div:4.781657, acc:0.965122\n","epoch:[40], D_loss:0.540786, G_loss:3.227156, G_div:4.833047, acc:0.967613\n","epoch:[41], D_loss:0.484414, G_loss:3.034994, G_div:4.895392, acc:0.978077\n","epoch:[42], D_loss:0.595279, G_loss:2.982671, G_div:4.852588, acc:0.978077\n","epoch:[43], D_loss:0.546818, G_loss:2.959561, G_div:4.841643, acc:0.976084\n","epoch:[44], D_loss:0.494545, G_loss:2.937648, G_div:4.873321, acc:0.978575\n","epoch:[45], D_loss:0.484344, G_loss:2.918121, G_div:4.908043, acc:0.975585\n","epoch:[46], D_loss:0.552245, G_loss:2.871177, G_div:4.905696, acc:0.969606\n","epoch:[47], D_loss:0.403011, G_loss:3.185680, G_div:4.850039, acc:0.970603\n","epoch:[48], D_loss:0.511742, G_loss:2.899617, G_div:5.018089, acc:0.971101\n","epoch:[49], D_loss:0.466455, G_loss:3.103711, G_div:4.824181, acc:0.975087\n","epoch:[50], D_loss:0.428462, G_loss:3.133790, G_div:4.767979, acc:0.959143\n","epoch:[51], D_loss:0.525472, G_loss:3.272161, G_div:4.850430, acc:0.972098\n","epoch:[52], D_loss:0.448542, G_loss:3.087513, G_div:4.907983, acc:0.975585\n","epoch:[53], D_loss:0.484748, G_loss:3.156184, G_div:4.871737, acc:0.977578\n","epoch:[54], D_loss:0.512791, G_loss:3.244504, G_div:4.912287, acc:0.976582\n","epoch:[55], D_loss:0.426505, G_loss:3.066204, G_div:4.836724, acc:0.973094\n","epoch:[56], D_loss:0.405961, G_loss:3.378817, G_div:4.888223, acc:0.968112\n","epoch:[57], D_loss:0.469118, G_loss:3.422160, G_div:4.790031, acc:0.965122\n","epoch:[58], D_loss:0.384265, G_loss:3.160170, G_div:4.929901, acc:0.973094\n","epoch:[59], D_loss:0.484455, G_loss:3.332462, G_div:4.878722, acc:0.974589\n","epoch:[60], D_loss:0.453806, G_loss:3.392217, G_div:4.978542, acc:0.968610\n","epoch:[61], D_loss:0.500237, G_loss:3.341596, G_div:4.954960, acc:0.983558\n","epoch:[62], D_loss:0.414754, G_loss:3.511364, G_div:4.921887, acc:0.975585\n","epoch:[63], D_loss:0.437368, G_loss:3.407443, G_div:4.941922, acc:0.968112\n","epoch:[64], D_loss:0.412766, G_loss:3.359284, G_div:4.879908, acc:0.972098\n","epoch:[65], D_loss:0.421534, G_loss:3.467849, G_div:4.897107, acc:0.966119\n","epoch:[66], D_loss:0.421035, G_loss:3.260715, G_div:4.874461, acc:0.974589\n","epoch:[67], D_loss:0.387655, G_loss:3.673973, G_div:4.989909, acc:0.978077\n","epoch:[68], D_loss:0.525372, G_loss:3.375004, G_div:4.819474, acc:0.973592\n","epoch:[69], D_loss:0.467928, G_loss:3.209123, G_div:5.007983, acc:0.976582\n","epoch:[70], D_loss:0.369958, G_loss:3.624171, G_div:4.813512, acc:0.981565\n","epoch:[71], D_loss:0.337899, G_loss:3.560757, G_div:5.000965, acc:0.979073\n","epoch:[72], D_loss:0.403677, G_loss:3.395604, G_div:4.937752, acc:0.978077\n","epoch:[73], D_loss:0.396635, G_loss:3.565005, G_div:4.876788, acc:0.974091\n","epoch:[74], D_loss:0.286365, G_loss:3.627404, G_div:4.968371, acc:0.970603\n","epoch:[75], D_loss:0.338627, G_loss:3.753797, G_div:4.963378, acc:0.973094\n","epoch:[76], D_loss:0.486360, G_loss:3.583530, G_div:4.900348, acc:0.973592\n","epoch:[77], D_loss:0.302198, G_loss:3.689896, G_div:4.927863, acc:0.987544\n","epoch:[78], D_loss:0.443583, G_loss:3.968133, G_div:5.026009, acc:0.980568\n","epoch:[79], D_loss:0.350408, G_loss:3.722281, G_div:5.039699, acc:0.983558\n","epoch:[80], D_loss:0.357877, G_loss:3.712124, G_div:4.923989, acc:0.983059\n","epoch:[81], D_loss:0.337532, G_loss:3.920790, G_div:4.900644, acc:0.979571\n","epoch:[82], D_loss:0.256921, G_loss:4.046197, G_div:4.934459, acc:0.979073\n","epoch:[83], D_loss:0.406570, G_loss:3.821947, G_div:5.035570, acc:0.972098\n","epoch:[84], D_loss:0.404991, G_loss:3.667921, G_div:4.864520, acc:0.977578\n","epoch:[85], D_loss:0.308019, G_loss:3.655951, G_div:4.856665, acc:0.975585\n","epoch:[86], D_loss:0.373389, G_loss:3.952233, G_div:4.905600, acc:0.981565\n","epoch:[87], D_loss:0.374914, G_loss:3.795993, G_div:5.084460, acc:0.984554\n","epoch:[88], D_loss:0.365218, G_loss:4.120669, G_div:5.051832, acc:0.979073\n","epoch:[89], D_loss:0.364905, G_loss:4.115824, G_div:4.824096, acc:0.978077\n","epoch:[90], D_loss:0.365334, G_loss:3.915884, G_div:4.926091, acc:0.984554\n","epoch:[91], D_loss:0.298637, G_loss:3.976448, G_div:5.066177, acc:0.978077\n","epoch:[92], D_loss:0.311865, G_loss:4.011164, G_div:5.075663, acc:0.969606\n","epoch:[93], D_loss:0.286410, G_loss:4.104635, G_div:4.849845, acc:0.976582\n","epoch:[94], D_loss:0.394610, G_loss:3.991186, G_div:4.870706, acc:0.980070\n","epoch:[95], D_loss:0.341210, G_loss:3.949008, G_div:4.975026, acc:0.977080\n","epoch:[96], D_loss:0.305590, G_loss:4.175503, G_div:4.979799, acc:0.983558\n","epoch:[97], D_loss:0.333979, G_loss:4.143707, G_div:4.870144, acc:0.982561\n","epoch:[98], D_loss:0.271937, G_loss:4.045318, G_div:5.035741, acc:0.982063\n","epoch:[99], D_loss:0.375240, G_loss:4.281250, G_div:5.011730, acc:0.981565\n","epoch:[100], D_loss:0.321049, G_loss:4.001862, G_div:5.084946, acc:0.981565\n","epoch:[101], D_loss:0.249861, G_loss:4.177936, G_div:4.982638, acc:0.976084\n","epoch:[102], D_loss:0.283439, G_loss:4.169811, G_div:4.968315, acc:0.979073\n","epoch:[103], D_loss:0.257648, G_loss:4.249548, G_div:4.996910, acc:0.979571\n","epoch:[104], D_loss:0.362120, G_loss:4.339637, G_div:4.929707, acc:0.979571\n","epoch:[105], D_loss:0.314614, G_loss:4.059369, G_div:5.049018, acc:0.981565\n","epoch:[106], D_loss:0.252215, G_loss:4.406700, G_div:4.970993, acc:0.979571\n","epoch:[107], D_loss:0.291244, G_loss:4.400174, G_div:4.999106, acc:0.986049\n","epoch:[108], D_loss:0.317124, G_loss:4.217345, G_div:4.931256, acc:0.985551\n","epoch:[109], D_loss:0.321775, G_loss:4.209711, G_div:5.026572, acc:0.981066\n","epoch:[110], D_loss:0.309416, G_loss:4.412971, G_div:4.951663, acc:0.976084\n","epoch:[111], D_loss:0.312036, G_loss:4.310010, G_div:4.883691, acc:0.980070\n","epoch:[112], D_loss:0.205334, G_loss:4.301167, G_div:5.013151, acc:0.974091\n","epoch:[113], D_loss:0.285486, G_loss:4.539053, G_div:4.972362, acc:0.976582\n","epoch:[114], D_loss:0.336662, G_loss:4.262197, G_div:5.035538, acc:0.962133\n","epoch:[115], D_loss:0.284239, G_loss:4.380132, G_div:4.852884, acc:0.980070\n","epoch:[116], D_loss:0.271453, G_loss:4.602978, G_div:5.001558, acc:0.977578\n","epoch:[117], D_loss:0.222437, G_loss:4.843010, G_div:4.951659, acc:0.978575\n","epoch:[118], D_loss:0.296753, G_loss:4.631203, G_div:5.084271, acc:0.985551\n","epoch:[119], D_loss:0.298867, G_loss:4.330062, G_div:5.028846, acc:0.983059\n","epoch:[120], D_loss:0.226877, G_loss:4.488538, G_div:4.997721, acc:0.976084\n","epoch:[121], D_loss:0.256245, G_loss:4.526866, G_div:4.864729, acc:0.985551\n","epoch:[122], D_loss:0.225088, G_loss:4.640373, G_div:4.881889, acc:0.988540\n","epoch:[123], D_loss:0.271810, G_loss:4.545433, G_div:5.096379, acc:0.977080\n","epoch:[124], D_loss:0.323015, G_loss:4.449784, G_div:5.107046, acc:0.984554\n","epoch:[125], D_loss:0.330639, G_loss:4.376393, G_div:4.992406, acc:0.984554\n","epoch:[126], D_loss:0.259319, G_loss:4.563366, G_div:5.027000, acc:0.975087\n","epoch:[127], D_loss:0.190475, G_loss:4.678895, G_div:4.899914, acc:0.978575\n","epoch:[128], D_loss:0.291733, G_loss:4.658851, G_div:4.947717, acc:0.982561\n","epoch:[129], D_loss:0.290366, G_loss:4.314169, G_div:5.066066, acc:0.983059\n","epoch:[130], D_loss:0.266422, G_loss:4.342343, G_div:4.963724, acc:0.980568\n","epoch:[131], D_loss:0.186835, G_loss:4.846246, G_div:4.921539, acc:0.975087\n","epoch:[132], D_loss:0.215062, G_loss:4.842162, G_div:4.963571, acc:0.979073\n","epoch:[133], D_loss:0.211993, G_loss:4.889072, G_div:4.896715, acc:0.974589\n","epoch:[134], D_loss:0.230395, G_loss:4.717854, G_div:5.078064, acc:0.974589\n","epoch:[135], D_loss:0.263385, G_loss:4.557858, G_div:5.007365, acc:0.986547\n","epoch:[136], D_loss:0.306958, G_loss:4.785673, G_div:5.015252, acc:0.990035\n","epoch:[137], D_loss:0.318935, G_loss:4.793983, G_div:4.944240, acc:0.977578\n","epoch:[138], D_loss:0.313920, G_loss:4.594985, G_div:4.969416, acc:0.982063\n","epoch:[139], D_loss:0.204533, G_loss:4.708179, G_div:5.008139, acc:0.982561\n","epoch:[140], D_loss:0.246356, G_loss:4.717002, G_div:4.996751, acc:0.983558\n","epoch:[141], D_loss:0.147291, G_loss:5.032285, G_div:4.857328, acc:0.980070\n","epoch:[142], D_loss:0.195392, G_loss:5.050197, G_div:4.990102, acc:0.985052\n","epoch:[143], D_loss:0.164659, G_loss:5.095862, G_div:5.022980, acc:0.981565\n","epoch:[144], D_loss:0.290294, G_loss:5.047890, G_div:4.986901, acc:0.974091\n","epoch:[145], D_loss:0.315556, G_loss:4.884066, G_div:4.967904, acc:0.979073\n","epoch:[146], D_loss:0.295365, G_loss:4.930659, G_div:4.922105, acc:0.980070\n","epoch:[147], D_loss:0.225528, G_loss:5.022437, G_div:4.914329, acc:0.982561\n","epoch:[148], D_loss:0.200965, G_loss:5.172215, G_div:4.973505, acc:0.984056\n","epoch:[149], D_loss:0.264689, G_loss:4.893949, G_div:4.934765, acc:0.985551\n","epoch:[150], D_loss:0.252931, G_loss:4.987657, G_div:5.006245, acc:0.977080\n","epoch:[151], D_loss:0.197231, G_loss:4.949780, G_div:4.996008, acc:0.983059\n","epoch:[152], D_loss:0.164072, G_loss:5.185478, G_div:4.934017, acc:0.988042\n","epoch:[153], D_loss:0.162452, G_loss:5.408421, G_div:5.038144, acc:0.982561\n","epoch:[154], D_loss:0.350120, G_loss:5.321713, G_div:4.930737, acc:0.985052\n","epoch:[155], D_loss:0.231817, G_loss:4.891149, G_div:4.919486, acc:0.976582\n","epoch:[156], D_loss:0.167752, G_loss:5.341868, G_div:4.947576, acc:0.978575\n","epoch:[157], D_loss:0.236355, G_loss:4.931878, G_div:5.110590, acc:0.985551\n","epoch:[158], D_loss:0.148557, G_loss:5.442758, G_div:5.033832, acc:0.984554\n","epoch:[159], D_loss:0.235909, G_loss:5.168695, G_div:5.131662, acc:0.982561\n","epoch:[160], D_loss:0.292157, G_loss:4.979342, G_div:4.999069, acc:0.975087\n","epoch:[161], D_loss:0.210180, G_loss:4.838577, G_div:5.057602, acc:0.974589\n","epoch:[162], D_loss:0.195760, G_loss:5.184958, G_div:5.057834, acc:0.989537\n","epoch:[163], D_loss:0.196620, G_loss:4.948730, G_div:5.004851, acc:0.984554\n","epoch:[164], D_loss:0.207129, G_loss:5.245577, G_div:5.105049, acc:0.982063\n","epoch:[165], D_loss:0.264433, G_loss:4.926810, G_div:5.165251, acc:0.983059\n","epoch:[166], D_loss:0.230320, G_loss:5.057526, G_div:4.972019, acc:0.988042\n","epoch:[167], D_loss:0.159685, G_loss:5.186196, G_div:5.027182, acc:0.981565\n","epoch:[168], D_loss:0.141312, G_loss:5.610869, G_div:5.134922, acc:0.977080\n","epoch:[169], D_loss:0.183368, G_loss:5.167340, G_div:5.061325, acc:0.985551\n","epoch:[170], D_loss:0.275057, G_loss:5.257225, G_div:5.088248, acc:0.977578\n","epoch:[171], D_loss:0.253940, G_loss:5.235233, G_div:5.045181, acc:0.984056\n","epoch:[172], D_loss:0.224954, G_loss:5.217584, G_div:4.943273, acc:0.983059\n","epoch:[173], D_loss:0.205323, G_loss:5.208117, G_div:4.932532, acc:0.978077\n","epoch:[174], D_loss:0.184007, G_loss:5.455428, G_div:4.979637, acc:0.984056\n","epoch:[175], D_loss:0.124438, G_loss:5.784094, G_div:5.007533, acc:0.983558\n","epoch:[176], D_loss:0.152041, G_loss:5.155096, G_div:5.046967, acc:0.985052\n","epoch:[177], D_loss:0.248799, G_loss:5.544724, G_div:5.045655, acc:0.984056\n","epoch:[178], D_loss:0.134950, G_loss:5.782050, G_div:4.925814, acc:0.980568\n","epoch:[179], D_loss:0.233608, G_loss:5.575677, G_div:4.960938, acc:0.982063\n","epoch:[180], D_loss:0.230628, G_loss:5.155329, G_div:5.009693, acc:0.984554\n","epoch:[181], D_loss:0.153950, G_loss:5.419745, G_div:4.987278, acc:0.979571\n","epoch:[182], D_loss:0.274873, G_loss:5.140194, G_div:5.070021, acc:0.981565\n","epoch:[183], D_loss:0.203413, G_loss:5.093654, G_div:5.084177, acc:0.978077\n","epoch:[184], D_loss:0.136846, G_loss:5.925056, G_div:5.071673, acc:0.977578\n","epoch:[185], D_loss:0.122146, G_loss:5.760146, G_div:4.996615, acc:0.976582\n","epoch:[186], D_loss:0.304363, G_loss:5.847733, G_div:5.046806, acc:0.974091\n","epoch:[187], D_loss:0.267876, G_loss:5.222504, G_div:4.940547, acc:0.973094\n","epoch:[188], D_loss:0.179328, G_loss:5.304698, G_div:4.963921, acc:0.963129\n","epoch:[189], D_loss:0.187478, G_loss:5.559610, G_div:4.997402, acc:0.975585\n","epoch:[190], D_loss:0.171067, G_loss:5.396259, G_div:4.971986, acc:0.974589\n","epoch:[191], D_loss:0.096417, G_loss:5.764168, G_div:5.048109, acc:0.977080\n","epoch:[192], D_loss:0.285104, G_loss:5.292486, G_div:5.004829, acc:0.984056\n","epoch:[193], D_loss:0.218803, G_loss:5.402611, G_div:5.040856, acc:0.984056\n","epoch:[194], D_loss:0.116371, G_loss:5.415934, G_div:5.011800, acc:0.983059\n","epoch:[195], D_loss:0.136803, G_loss:5.513840, G_div:5.102992, acc:0.976582\n","epoch:[196], D_loss:0.163097, G_loss:5.819770, G_div:5.081151, acc:0.979571\n","epoch:[197], D_loss:0.215504, G_loss:5.323138, G_div:5.063356, acc:0.975585\n","epoch:[198], D_loss:0.255860, G_loss:5.503329, G_div:4.972080, acc:0.977080\n","epoch:[199], D_loss:0.181798, G_loss:5.473525, G_div:4.880772, acc:0.981565\n"]}]}]}